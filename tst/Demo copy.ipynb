{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Sri Lankan CKD Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= {\"M\":1,\"F\":0}\n",
    "\n",
    "df[\"gender\"]=df[\"gender\"].map(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"cru\",axis =1)\n",
    "df = df.drop(\"ua\",axis =1)\n",
    "df = df.drop(\"iron\",axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Missing Values per Row:\n",
      "0      6\n",
      "1      2\n",
      "2      1\n",
      "3      2\n",
      "4      2\n",
      "      ..\n",
      "401    4\n",
      "402    0\n",
      "403    1\n",
      "404    4\n",
      "405    1\n",
      "Length: 406, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values_per_row = df.isnull().sum(axis=1)\n",
    "\n",
    "print(\"Number of Missing Values per Row:\")\n",
    "print(missing_values_per_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered DataFrame:\n",
      "      id   age  weight  gender       cr    al    gl     na    ca    k     cl  \\\n",
      "0      1  72.0   52.00       1   249.43  34.9   NaN  142.0  2.43  5.0  113.0   \n",
      "1      2  76.0   52.00       1   216.05  41.3   NaN  145.0  2.40  4.7  114.0   \n",
      "2      3  60.0   80.40       1   155.40  33.7   NaN  135.0  2.00  4.2  103.0   \n",
      "3      4  65.0   53.40       0   127.50  41.8   NaN  138.0  2.80  4.4  100.0   \n",
      "4      5  59.0   60.40       1   172.71  39.7   NaN  128.0  2.20  3.6   91.0   \n",
      "..   ...   ...     ...     ...      ...   ...   ...    ...   ...  ...    ...   \n",
      "401  402  48.0   48.00       1  1167.62   NaN   NaN  134.0   NaN  4.1   94.0   \n",
      "402  403  46.0   55.00       1   211.20  37.2  37.9  144.0  2.40  4.3  105.0   \n",
      "403  404  55.0   54.85       0   164.43  22.2  48.9  129.0   NaN  3.9   97.0   \n",
      "404  405  84.0   43.90       1   501.71   NaN   NaN  135.0   NaN  5.7   99.0   \n",
      "405  406  38.0   60.50       1   880.64  38.5  32.1  127.0   NaN  4.1   99.0   \n",
      "\n",
      "       pr   wbc   rbc    hg    plt  class  \n",
      "0     NaN   NaN   NaN   NaN    NaN      1  \n",
      "1     NaN  9.85  3.44  11.3  356.0      1  \n",
      "2    11.6  9.24  4.60   8.4  329.0      1  \n",
      "3     NaN  9.87  4.32  11.7  364.0      1  \n",
      "4     NaN  8.93  4.82  13.8  214.0      1  \n",
      "..    ...   ...   ...   ...    ...    ...  \n",
      "401   NaN  5.43  4.18  13.5  146.0      1  \n",
      "402  75.1  6.56  4.71  14.1  217.0      1  \n",
      "403  71.1  5.92  2.67   8.7   79.0      1  \n",
      "404   NaN  5.07  4.53  12.8  179.0      1  \n",
      "405  70.6  7.96  3.28   7.9  137.0      1  \n",
      "\n",
      "[395 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "threshold = 10\n",
    "filtered_data = df[missing_values_per_row <= threshold]\n",
    "\n",
    "print(\"\\nFiltered DataFrame:\")\n",
    "print(filtered_data)\n",
    "filtered_data.shape\n",
    "\n",
    "df = filtered_data.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'age', 'weight', 'gender', 'cr', 'al', 'gl', 'na', 'ca', 'k',\n",
       "       'cl', 'pr', 'wbc', 'rbc', 'hg', 'plt', 'class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df = df[['cr','age','hg','al','gender','na','gl','ca','class']].copy()\n",
    "# # df = df[['cr','age','weight','al','gender','k','ca','class']].copy()\n",
    "\n",
    "# # df = df[['age','hg','al','gender','na','gl','ca','class']].copy()\n",
    "\n",
    "# # df = df[['cr','age','hg','gender','na','class']].copy()\n",
    "\n",
    "# # df = df[['age', 'weight', 'gender', 'cr', 'al', 'gl', 'na', 'ca', 'k',\n",
    "# #        'cl', 'pr', 'wbc', 'rbc', 'hg', 'plt', 'class']].copy()\n",
    "\n",
    "\n",
    "# df = df[['age','hg','gender','na','ca','class']].copy()\n",
    "\n",
    "# # df = df[['cr','hg','al','na','gl','ca','class']].copy()\n",
    "\n",
    "# # df = df[['cr','al','na','gl','ca','cl','k','class','rbc','pr']].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>gender</th>\n",
       "      <th>cr</th>\n",
       "      <th>al</th>\n",
       "      <th>gl</th>\n",
       "      <th>na</th>\n",
       "      <th>ca</th>\n",
       "      <th>k</th>\n",
       "      <th>cl</th>\n",
       "      <th>pr</th>\n",
       "      <th>wbc</th>\n",
       "      <th>rbc</th>\n",
       "      <th>hg</th>\n",
       "      <th>plt</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>249.43</td>\n",
       "      <td>34.9</td>\n",
       "      <td>35.721429</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2.43</td>\n",
       "      <td>5.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>48.342857</td>\n",
       "      <td>9.047857</td>\n",
       "      <td>4.312143</td>\n",
       "      <td>12.457143</td>\n",
       "      <td>270.714286</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>216.05</td>\n",
       "      <td>41.3</td>\n",
       "      <td>38.600000</td>\n",
       "      <td>145.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>4.7</td>\n",
       "      <td>114.0</td>\n",
       "      <td>53.750000</td>\n",
       "      <td>9.850000</td>\n",
       "      <td>3.440000</td>\n",
       "      <td>11.300000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.0</td>\n",
       "      <td>80.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>155.40</td>\n",
       "      <td>33.7</td>\n",
       "      <td>36.800000</td>\n",
       "      <td>135.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.2</td>\n",
       "      <td>103.0</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>9.240000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>329.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.0</td>\n",
       "      <td>53.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.50</td>\n",
       "      <td>41.8</td>\n",
       "      <td>39.271429</td>\n",
       "      <td>138.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>4.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>76.721429</td>\n",
       "      <td>9.870000</td>\n",
       "      <td>4.320000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59.0</td>\n",
       "      <td>60.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>172.71</td>\n",
       "      <td>39.7</td>\n",
       "      <td>33.508571</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.6</td>\n",
       "      <td>91.0</td>\n",
       "      <td>53.442857</td>\n",
       "      <td>8.930000</td>\n",
       "      <td>4.820000</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  weight  gender      cr    al         gl     na    ca    k     cl  \\\n",
       "0  72.0    52.0     1.0  249.43  34.9  35.721429  142.0  2.43  5.0  113.0   \n",
       "1  76.0    52.0     1.0  216.05  41.3  38.600000  145.0  2.40  4.7  114.0   \n",
       "2  60.0    80.4     1.0  155.40  33.7  36.800000  135.0  2.00  4.2  103.0   \n",
       "3  65.0    53.4     0.0  127.50  41.8  39.271429  138.0  2.80  4.4  100.0   \n",
       "4  59.0    60.4     1.0  172.71  39.7  33.508571  128.0  2.20  3.6   91.0   \n",
       "\n",
       "          pr       wbc       rbc         hg         plt  class  \n",
       "0  48.342857  9.047857  4.312143  12.457143  270.714286    1.0  \n",
       "1  53.750000  9.850000  3.440000  11.300000  356.000000    1.0  \n",
       "2  11.600000  9.240000  4.600000   8.400000  329.000000    1.0  \n",
       "3  76.721429  9.870000  4.320000  11.700000  364.000000    1.0  \n",
       "4  53.442857  8.930000  4.820000  13.800000  214.000000    1.0  "
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=14)\n",
    "\n",
    "# Perform the imputation\n",
    "df_imputed_1 = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "df_imputed_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_imputed_1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature  Importance\n",
      "3       cr    0.391064\n",
      "13      hg    0.141013\n",
      "12     rbc    0.127357\n",
      "10      pr    0.082959\n",
      "7       ca    0.068265\n",
      "5       gl    0.039216\n",
      "4       al    0.029813\n",
      "9       cl    0.029518\n",
      "6       na    0.018806\n",
      "0      age    0.017125\n",
      "11     wbc    0.015910\n",
      "14     plt    0.012258\n",
      "8        k    0.012238\n",
      "1   weight    0.011295\n",
      "2   gender    0.003163\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize and fit the model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(df.drop(columns=['class']), df['class'])  # Adjust 'target' to your actual target column\n",
    "\n",
    "# Get feature importances\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to associate feature names with their importance\n",
    "feature_importances = pd.DataFrame({'Feature': df.drop(columns=['class']).columns, 'Importance': importances})\n",
    "\n",
    "# Sort by importance in descending order\n",
    "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "print(feature_importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature  Importance\n",
      "3       cr    0.688327\n",
      "12     rbc    0.062222\n",
      "4       al    0.037059\n",
      "13      hg    0.030037\n",
      "1   weight    0.027645\n",
      "6       na    0.024315\n",
      "9       cl    0.021074\n",
      "14     plt    0.020087\n",
      "0      age    0.019673\n",
      "7       ca    0.017700\n",
      "5       gl    0.016436\n",
      "10      pr    0.016336\n",
      "8        k    0.009951\n",
      "11     wbc    0.009140\n",
      "2   gender    0.000000\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize and fit the model\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(df.drop(columns=['class']), df['class'])  # Adjust 'target' to your actual target column\n",
    "\n",
    "# Get feature importances\n",
    "importances = xgb.feature_importances_\n",
    "\n",
    "# Create a DataFrame to associate feature names with their importance\n",
    "feature_importances = pd.DataFrame({'Feature': df.drop(columns=['class']).columns, 'Importance': importances})\n",
    "\n",
    "# Sort by importance in descending order\n",
    "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "print(feature_importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature  Importance\n",
      "3       cr    0.333165\n",
      "13      hg    0.014684\n",
      "12     rbc    0.010127\n",
      "1   weight    0.007848\n",
      "10      pr    0.006835\n",
      "7       ca    0.006582\n",
      "8        k    0.005063\n",
      "9       cl    0.004810\n",
      "11     wbc    0.004304\n",
      "5       gl    0.003797\n",
      "6       na    0.002025\n",
      "14     plt    0.002025\n",
      "4       al    0.001772\n",
      "0      age    0.000253\n",
      "2   gender    0.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Initialize and fit the model (use any model like RandomForestClassifier, etc.)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(df.drop(columns=['class']), df['class'])\n",
    "\n",
    "# Perform permutation importance\n",
    "result = permutation_importance(model, df.drop(columns=['class']), df['class'], n_repeats=10, random_state=42)\n",
    "\n",
    "# Create a DataFrame for feature importance\n",
    "feature_importances = pd.DataFrame({'Feature': df.drop(columns=['class']).columns, 'Importance': result.importances_mean})\n",
    "\n",
    "# Sort by importance in descending order\n",
    "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "print(feature_importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         1\n",
       "weight      4\n",
       "gender      0\n",
       "cr          8\n",
       "al        188\n",
       "gl        323\n",
       "na         29\n",
       "ca        304\n",
       "k          28\n",
       "cl        182\n",
       "pr        319\n",
       "wbc        29\n",
       "rbc        32\n",
       "hg         22\n",
       "plt        25\n",
       "dtype: int64"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature  Mutual Information\n",
      "3       cr            0.559555\n",
      "7       ca            0.379461\n",
      "12     rbc            0.361880\n",
      "13      hg            0.342068\n",
      "10      pr            0.341970\n",
      "9       cl            0.311991\n",
      "5       gl            0.125275\n",
      "4       al            0.122019\n",
      "11     wbc            0.120699\n",
      "6       na            0.099294\n",
      "8        k            0.092720\n",
      "0      age            0.056118\n",
      "1   weight            0.044173\n",
      "14     plt            0.033167\n",
      "2   gender            0.021850\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame, and 'target' is your target column\n",
    "X = df.drop(columns=['class'])\n",
    "y = df['class']\n",
    "\n",
    "# Calculate mutual information\n",
    "mi = mutual_info_classif(X, y)\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "mi_df = pd.DataFrame({'Feature': X.columns, 'Mutual Information': mi})\n",
    "\n",
    "# Sort by mutual information in descending order\n",
    "mi_df = mi_df.sort_values(by='Mutual Information', ascending=False)\n",
    "print(mi_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: Index(['age', 'cr', 'al', 'gl', 'na', 'pr', 'wbc', 'rbc', 'hg', 'plt'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import pandas as pd\n",
    "\n",
    "# Select the best 10 features using the chi-squared test\n",
    "selector = SelectKBest(chi2, k=10)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = selector.get_support(indices=True)\n",
    "\n",
    "# Display the selected features\n",
    "feature_names = X.columns[selected_features]\n",
    "print(\"Selected Features:\", feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature  Ranking  Selected\n",
      "3       cr        1      True\n",
      "13      hg        2     False\n",
      "12     rbc        3     False\n",
      "10      pr        4     False\n",
      "7       ca        5     False\n",
      "5       gl        6     False\n",
      "9       cl        7     False\n",
      "4       al        8     False\n",
      "14     plt        9     False\n",
      "0      age       10     False\n",
      "6       na       11     False\n",
      "8        k       12     False\n",
      "11     wbc       13     False\n",
      "1   weight       14     False\n",
      "2   gender       15     False\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the model (Random Forest in this case)\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Use RFECV for automatic feature selection\n",
    "rfecv = RFECV(estimator=model, step=1, cv=5, scoring='accuracy')\n",
    "rfecv.fit(X, y)\n",
    "\n",
    "# Get the ranking of features and the number of optimal features\n",
    "optimal_features = rfecv.support_\n",
    "ranking = rfecv.ranking_\n",
    "\n",
    "# Create a DataFrame to show the features and their rankings\n",
    "rfecv_df = pd.DataFrame({'Feature': X.columns, 'Ranking': ranking, 'Selected': optimal_features})\n",
    "print(rfecv_df.sort_values(by='Ranking'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: Index(['age', 'cr', 'al', 'gl', 'na', 'ca', 'cl', 'pr', 'rbc', 'hg'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Initialize Boruta feature selection\n",
    "boruta_selector = BorutaPy(estimator=model, n_estimators='auto', random_state=42)\n",
    "\n",
    "# Fit the Boruta selector\n",
    "boruta_selector.fit(X.values, y.values)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X.columns[boruta_selector.support_]\n",
    "print(\"Selected Features:\", selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hg</th>\n",
       "      <th>gender</th>\n",
       "      <th>na</th>\n",
       "      <th>ca</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72.0</td>\n",
       "      <td>12.373684</td>\n",
       "      <td>1.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2.43</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76.0</td>\n",
       "      <td>11.300000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.0</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.0</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59.0</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age         hg  gender     na    ca  class\n",
       "0  72.0  12.373684     1.0  142.0  2.43    1.0\n",
       "1  76.0  11.300000     1.0  145.0  2.40    1.0\n",
       "2  60.0   8.400000     1.0  135.0  2.00    1.0\n",
       "3  65.0  11.700000     0.0  138.0  2.80    1.0\n",
       "4  59.0  13.800000     1.0  128.0  2.20    1.0"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=19)\n",
    "\n",
    "# Perform the imputation\n",
    "df_imputed_2 = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "df_imputed_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hg</th>\n",
       "      <th>gender</th>\n",
       "      <th>na</th>\n",
       "      <th>ca</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72.0</td>\n",
       "      <td>12.493333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2.43</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76.0</td>\n",
       "      <td>11.300000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.0</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.0</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59.0</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age         hg  gender     na    ca  class\n",
       "0  72.0  12.493333     1.0  142.0  2.43    1.0\n",
       "1  76.0  11.300000     1.0  145.0  2.40    1.0\n",
       "2  60.0   8.400000     1.0  135.0  2.00    1.0\n",
       "3  65.0  11.700000     0.0  138.0  2.80    1.0\n",
       "4  59.0  13.800000     1.0  128.0  2.20    1.0"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=15)\n",
    "\n",
    "# Perform the imputation\n",
    "df_imputed_3 = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "df_imputed_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hg</th>\n",
       "      <th>gender</th>\n",
       "      <th>na</th>\n",
       "      <th>ca</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72.0</td>\n",
       "      <td>12.41875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2.43</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76.0</td>\n",
       "      <td>11.30000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.0</td>\n",
       "      <td>8.40000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.0</td>\n",
       "      <td>11.70000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59.0</td>\n",
       "      <td>13.80000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age        hg  gender     na    ca  class\n",
       "0  72.0  12.41875     1.0  142.0  2.43    1.0\n",
       "1  76.0  11.30000     1.0  145.0  2.40    1.0\n",
       "2  60.0   8.40000     1.0  135.0  2.00    1.0\n",
       "3  65.0  11.70000     0.0  138.0  2.80    1.0\n",
       "4  59.0  13.80000     1.0  128.0  2.20    1.0"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=16)\n",
    "\n",
    "# Perform the imputation\n",
    "df_imputed_4 = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "df_imputed_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hg</th>\n",
       "      <th>gender</th>\n",
       "      <th>na</th>\n",
       "      <th>ca</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72.0</td>\n",
       "      <td>12.438462</td>\n",
       "      <td>1.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2.43</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76.0</td>\n",
       "      <td>11.300000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.0</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.0</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59.0</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age         hg  gender     na    ca  class\n",
       "0  72.0  12.438462     1.0  142.0  2.43    1.0\n",
       "1  76.0  11.300000     1.0  145.0  2.40    1.0\n",
       "2  60.0   8.400000     1.0  135.0  2.00    1.0\n",
       "3  65.0  11.700000     0.0  138.0  2.80    1.0\n",
       "4  59.0  13.800000     1.0  128.0  2.20    1.0"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=13)\n",
    "\n",
    "# Perform the imputation\n",
    "df_imputed_5 = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "df_imputed_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hg</th>\n",
       "      <th>gender</th>\n",
       "      <th>na</th>\n",
       "      <th>ca</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72.0</td>\n",
       "      <td>12.49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2.43</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76.0</td>\n",
       "      <td>11.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.0</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.0</td>\n",
       "      <td>11.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59.0</td>\n",
       "      <td>13.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age     hg  gender     na    ca  class\n",
       "0  72.0  12.49     1.0  142.0  2.43    1.0\n",
       "1  76.0  11.30     1.0  145.0  2.40    1.0\n",
       "2  60.0   8.40     1.0  135.0  2.00    1.0\n",
       "3  65.0  11.70     0.0  138.0  2.80    1.0\n",
       "4  59.0  13.80     1.0  128.0  2.20    1.0"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=10)\n",
    "\n",
    "# Perform the imputation\n",
    "df_imputed_6 = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "df_imputed_6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_imputed = df_imputed.round(1)\n",
    "X_1 = df_imputed_1.drop(columns='class')\n",
    "y_1 = df_imputed_1['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_imputed = df_imputed.round(1)\n",
    "X_2 = df_imputed_2.drop(columns='class')\n",
    "y_2 = df_imputed_2['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_imputed = df_imputed.round(1)\n",
    "X_3 = df_imputed_3.drop(columns='class')\n",
    "y_3 = df_imputed_3['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_imputed = df_imputed.round(1)\n",
    "X_4 = df_imputed_4.drop(columns='class')\n",
    "y_4 = df_imputed_4['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_imputed = df_imputed.round(1)\n",
    "X_5 = df_imputed_5.drop(columns='class')\n",
    "y_5 = df_imputed_5['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_imputed = df_imputed.round(1)\n",
    "X_6 = df_imputed_6.drop(columns='class')\n",
    "y_6 = df_imputed_6['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_1, y_1, test_size=0.2, random_state=42)\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size=0.2, random_state=42)\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_3, y_3, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_4, X_test_4, y_train_4, y_test_4 = train_test_split(X_4, y_4, test_size=0.2, random_state=42)\n",
    "X_train_5, X_test_5, y_train_5, y_test_5 = train_test_split(X_5, y_5, test_size=0.2, random_state=42)\n",
    "X_train_6, X_test_6, y_train_6, y_test_6 = train_test_split(X_6, y_6, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Final Test Accuracy: 83.54%\n",
      "Recall: 0.87037\n",
      "Precision: 0.88679\n",
      "F1 Score: 0.87850\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix, cohen_kappa_score, f1_score\n",
    "\n",
    "\n",
    "# Assuming you have X_train_1, X_train_2, X_train_3, y_train_1, y_train_2, y_train_3, X_test, y_test\n",
    "\n",
    "# Function to build the model\n",
    "def build_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    # model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Scale the datasets\n",
    "scaler_1 = StandardScaler()\n",
    "scaler_2 = StandardScaler()\n",
    "scaler_3 = StandardScaler()\n",
    "scaler_4 = StandardScaler()\n",
    "scaler_5 = StandardScaler()\n",
    "scaler_6 = StandardScaler()\n",
    "\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_1_scaled = scaler_1.fit_transform(X_train_1)\n",
    "X_train_2_scaled = scaler_2.fit_transform(X_train_2)\n",
    "X_train_3_scaled = scaler_3.fit_transform(X_train_3)\n",
    "X_train_4_scaled = scaler_4.fit_transform(X_train_4)\n",
    "X_train_5_scaled = scaler_5.fit_transform(X_train_5)\n",
    "X_train_6_scaled = scaler_6.fit_transform(X_train_6)\n",
    "\n",
    "\n",
    "# Transform the test data using the scalers fitted on respective training sets\n",
    "X_test_scaled_1 = scaler_1.transform(X_test_1)\n",
    "X_test_scaled_2 = scaler_2.transform(X_test_2)\n",
    "X_test_scaled_3 = scaler_3.transform(X_test_3)\n",
    "X_test_scaled_4 = scaler_4.transform(X_test_4)\n",
    "X_test_scaled_5 = scaler_5.transform(X_test_5)\n",
    "X_test_scaled_6 = scaler_6.transform(X_test_6)\n",
    "\n",
    "\n",
    "# Build and train the models on scaled data\n",
    "model_1 = build_model(X_train_1_scaled.shape[1])\n",
    "model_2 = build_model(X_train_2_scaled.shape[1])\n",
    "model_3 = build_model(X_train_3_scaled.shape[1])\n",
    "model_4 = build_model(X_train_4_scaled.shape[1])\n",
    "model_5 = build_model(X_train_5_scaled.shape[1])\n",
    "model_6 = build_model(X_train_6_scaled.shape[1])\n",
    "\n",
    "\n",
    "# Train the models\n",
    "model_1.fit(X_train_1_scaled, y_train_1, epochs=50, batch_size=10, verbose=0)\n",
    "model_2.fit(X_train_2_scaled, y_train_2, epochs=50, batch_size=10, verbose=0)\n",
    "model_3.fit(X_train_3_scaled, y_train_3, epochs=50, batch_size=10, verbose=0)\n",
    "model_4.fit(X_train_4_scaled, y_train_4, epochs=50, batch_size=10, verbose=0)\n",
    "model_5.fit(X_train_5_scaled, y_train_5, epochs=50, batch_size=10, verbose=0)\n",
    "model_6.fit(X_train_6_scaled, y_train_6, epochs=50, batch_size=10, verbose=0)\n",
    "\n",
    "# Get predicted probabilities for each model using scaled test sets\n",
    "y_pred_prob_1 = model_1.predict(X_test_scaled_1)\n",
    "y_pred_prob_2 = model_2.predict(X_test_scaled_2)\n",
    "y_pred_prob_3 = model_3.predict(X_test_scaled_3)\n",
    "y_pred_prob_4 = model_4.predict(X_test_scaled_4)\n",
    "y_pred_prob_5 = model_5.predict(X_test_scaled_5)\n",
    "y_pred_prob_6 = model_6.predict(X_test_scaled_6)\n",
    "\n",
    "\n",
    "# Averaging the predicted probabilities from all three models\n",
    "y_pred_prob_avg = (y_pred_prob_1 + y_pred_prob_2 + y_pred_prob_3+y_pred_prob_4+y_pred_prob_5+y_pred_prob_6) / 6\n",
    "\n",
    "# Convert probabilities to binary labels (threshold = 0.5)\n",
    "y_pred_final = (y_pred_prob_avg > 0.5).astype(\"int32\")\n",
    "\n",
    "# Evaluate the accuracy of the final predictions\n",
    "accuracy = accuracy_score(y_test_1, y_pred_final)\n",
    "accuracy = accuracy_score(y_test_1, y_pred_final)\n",
    "recall = recall_score(y_test_1, y_pred_final)\n",
    "precision = precision_score(y_test_1, y_pred_final)\n",
    "f1 = f1_score(y_test_1, y_pred_final)\n",
    "print(f\"Final Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Recall: {recall:.5f}\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"F1 Score: {f1:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import StackingClassifier\n",
    "# from sklearn.datasets import load_iris\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# estimators = [\n",
    "#     ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
    "#     ('xgb', XGBClassifier(random_state=42))  # Replace LinearSVC with XGBClassifier\n",
    "# ]\n",
    "\n",
    "# # Define the stacking classifier with a logistic regression as the final estimator\n",
    "# clf = StackingClassifier(\n",
    "#     estimators=estimators, final_estimator=LogisticRegression()\n",
    "# )\n",
    "\n",
    "# # Fit the stacking classifier and evaluate on the test set\n",
    "# clf.fit(X_train_1, y_train_1)\n",
    "# score = clf.score(X_test_1, y_test_1)\n",
    "\n",
    "# # Display the accuracy score\n",
    "# print(f\"Stacking Classifier Accuracy: {score:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96203\n",
      "Recall: 0.96296\n",
      "Precision: 0.98113\n",
      "F1 Score: 0.97196\n",
      "Cohen's Kappa: 0.91316\n",
      "Confusion Matrix:\n",
      "[[24  1]\n",
      " [ 2 52]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf1 = XGBClassifier()\n",
    "clf2 = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[\n",
    "        ('lr', clf1), ('rf', clf2)], voting='hard')\n",
    "eclf1 = eclf1.fit(X_train_1, y_train_1)\n",
    "\n",
    "y_pred_1 = eclf1.predict(X_test_1)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test_1, y_pred_1)\n",
    "recall = recall_score(y_test_1, y_pred_1)\n",
    "precision = precision_score(y_test_1, y_pred_1)\n",
    "f1 = f1_score(y_test_1, y_pred_1)\n",
    "kappa = cohen_kappa_score(y_test_1, y_pred_1)\n",
    "conf_matrix = confusion_matrix(y_test_1, y_pred_1)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"F1 Score: {f1:.5f}\")\n",
    "print(f\"Cohen's Kappa: {kappa:.5f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.40506329113924\n",
      "Recall: 90.74074074074075\n",
      "Precision: 98.0\n",
      "F1 Score: 94.23076923076923\n",
      "Cohen's Kappa: 0.8316761363636364\n",
      "Confusion Matrix:\n",
      "[[24  1]\n",
      " [ 5 49]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k = 2 # Number of neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train_1, y_train_1)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = knn.predict(X_test_1)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test_1, y_pred)\n",
    "recall = recall_score(y_test_1, y_pred)\n",
    "precision = precision_score(y_test_1, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test_1, y_pred)\n",
    "kappa = cohen_kappa_score(y_test_1, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test_1, y_pred)\n",
    "f1 = f1_score(y_test_1, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy*100}\")\n",
    "print(f\"Recall: {recall*100}\")\n",
    "print(f\"Precision: {precision*100}\")\n",
    "print(f\"F1 Score: {f1*100}\")\n",
    "print(f\"Cohen's Kappa: {kappa}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Logistic Regression Evaluation ---\n",
      "Accuracy: 88.61%\n",
      "Recall: 87.04%\n",
      "Precision: 95.92%\n",
      "F1 Score: 91.26%\n",
      "Cohen's Kappa: 0.75\n",
      "Confusion Matrix:\n",
      "[[23  2]\n",
      " [ 7 47]]\n",
      "\n",
      "\n",
      "--- Decision Tree Evaluation ---\n",
      "Accuracy: 92.41%\n",
      "Recall: 90.74%\n",
      "Precision: 98.00%\n",
      "F1 Score: 94.23%\n",
      "Cohen's Kappa: 0.83\n",
      "Confusion Matrix:\n",
      "[[24  1]\n",
      " [ 5 49]]\n",
      "\n",
      "\n",
      "--- Random Forest Evaluation ---\n",
      "Accuracy: 96.20%\n",
      "Recall: 96.30%\n",
      "Precision: 98.11%\n",
      "F1 Score: 97.20%\n",
      "Cohen's Kappa: 0.91\n",
      "Confusion Matrix:\n",
      "[[24  1]\n",
      " [ 2 52]]\n",
      "\n",
      "\n",
      "--- AdaBoost Evaluation ---\n",
      "Accuracy: 93.67%\n",
      "Recall: 94.44%\n",
      "Precision: 96.23%\n",
      "F1 Score: 95.33%\n",
      "Cohen's Kappa: 0.86\n",
      "Confusion Matrix:\n",
      "[[23  2]\n",
      " [ 3 51]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, cohen_kappa_score\n",
    "\n",
    "# Initialize the models\n",
    "log_reg = LogisticRegression()\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "random_forest = RandomForestClassifier()\n",
    "adaboost = AdaBoostClassifier()\n",
    "\n",
    "# Fit the models to the training data\n",
    "log_reg.fit(X_train_1, y_train_1)\n",
    "decision_tree.fit(X_train_1, y_train_1)\n",
    "random_forest.fit(X_train_1, y_train_1)\n",
    "adaboost.fit(X_train_1, y_train_1)\n",
    "\n",
    "# Predict using Logistic Regression\n",
    "y_pred_logreg = log_reg.predict(X_test_1)\n",
    "# Predict using Decision Tree\n",
    "y_pred_dt = decision_tree.predict(X_test_1)\n",
    "# Predict using Random Forest\n",
    "y_pred_rf = random_forest.predict(X_test_1)\n",
    "# Predict using AdaBoost\n",
    "y_pred_adaboost = adaboost.predict(X_test_1)\n",
    "\n",
    "# Function to calculate and display the evaluation metrics\n",
    "def evaluate_model(y_test, y_pred, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f\"--- {model_name} Evaluation ---\")\n",
    "    print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "    print(f\"Recall: {recall*100:.2f}%\")\n",
    "    print(f\"Precision: {precision*100:.2f}%\")\n",
    "    print(f\"F1 Score: {f1*100:.2f}%\")\n",
    "    print(f\"Cohen's Kappa: {kappa:.2f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Evaluate each model\n",
    "evaluate_model(y_test_1, y_pred_logreg, \"Logistic Regression\")\n",
    "evaluate_model(y_test_1, y_pred_dt, \"Decision Tree\")\n",
    "evaluate_model(y_test_1, y_pred_rf, \"Random Forest\")\n",
    "evaluate_model(y_test_1, y_pred_adaboost, \"AdaBoost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.4609 - loss: 0.6941\n",
      "Epoch 2/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7320 - loss: 0.6535\n",
      "Epoch 3/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7782 - loss: 0.6170 \n",
      "Epoch 4/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8188 - loss: 0.5690 \n",
      "Epoch 5/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8032 - loss: 0.5204\n",
      "Epoch 6/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7910 - loss: 0.4859 \n",
      "Epoch 7/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8388 - loss: 0.4391\n",
      "Epoch 8/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8517 - loss: 0.4156\n",
      "Epoch 9/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8345 - loss: 0.3881  \n",
      "Epoch 10/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8680 - loss: 0.3656\n",
      "Epoch 11/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8899 - loss: 0.3119 \n",
      "Epoch 12/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8682 - loss: 0.3594 \n",
      "Epoch 13/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8907 - loss: 0.3207\n",
      "Epoch 14/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9111 - loss: 0.2918\n",
      "Epoch 15/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8973 - loss: 0.3070 \n",
      "Epoch 16/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9089 - loss: 0.3193 \n",
      "Epoch 17/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9122 - loss: 0.3216\n",
      "Epoch 18/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8915 - loss: 0.3216\n",
      "Epoch 19/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8968 - loss: 0.2721\n",
      "Epoch 20/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9096 - loss: 0.2880 \n",
      "Epoch 21/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9000 - loss: 0.3091 \n",
      "Epoch 22/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9183 - loss: 0.2392 \n",
      "Epoch 23/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9052 - loss: 0.2821\n",
      "Epoch 24/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9080 - loss: 0.2681 \n",
      "Epoch 25/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9064 - loss: 0.2946 \n",
      "Epoch 26/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9209 - loss: 0.2387\n",
      "Epoch 27/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9038 - loss: 0.2817 \n",
      "Epoch 28/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9266 - loss: 0.2348\n",
      "Epoch 29/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9134 - loss: 0.2438\n",
      "Epoch 30/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8965 - loss: 0.2384\n",
      "Epoch 31/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9275 - loss: 0.2263 \n",
      "Epoch 32/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9234 - loss: 0.2253 \n",
      "Epoch 33/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9244 - loss: 0.2128 \n",
      "Epoch 34/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8978 - loss: 0.2638 \n",
      "Epoch 35/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9021 - loss: 0.2693 \n",
      "Epoch 36/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9031 - loss: 0.2583  \n",
      "Epoch 37/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9146 - loss: 0.2248 \n",
      "Epoch 38/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9110 - loss: 0.2554 \n",
      "Epoch 39/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9112 - loss: 0.2530 \n",
      "Epoch 40/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9365 - loss: 0.2087 \n",
      "Epoch 41/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9452 - loss: 0.1821 \n",
      "Epoch 42/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9274 - loss: 0.2388 \n",
      "Epoch 43/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9148 - loss: 0.2516 \n",
      "Epoch 44/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9425 - loss: 0.1646 \n",
      "Epoch 45/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9177 - loss: 0.2171 \n",
      "Epoch 46/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9514 - loss: 0.1600\n",
      "Epoch 47/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9224 - loss: 0.2729 \n",
      "Epoch 48/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9232 - loss: 0.2058 \n",
      "Epoch 49/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9391 - loss: 0.1801 \n",
      "Epoch 50/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9333 - loss: 0.2273 \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "Test Accuracy: 84.81%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assume X and y are your features and labels from tabular data\n",
    "# Example: X = np.random.rand(1000, 10), y = np.random.randint(0, 2, 1000)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the input data (optional but recommended for neural networks)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_1)\n",
    "X_test = scaler.transform(X_test_1)\n",
    "\n",
    "# Reshape data to fit into a 1D CNN. New shape will be (samples, features, 1) for 1D convolution.\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Build the 1D CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# 1D convolutional layer with 32 filters and a kernel size of 2\n",
    "model.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "\n",
    "# Max pooling layer to downsample the data\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# Another 1D convolutional layer with 64 filters\n",
    "model.add(Conv1D(filters=16, kernel_size=2, activation='relu'))\n",
    "\n",
    "# Flatten the convolution output to feed it into a Dense layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer with 128 units and ReLU activation\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Output layer for binary classification (sigmoid activation)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train_1, epochs=50, batch_size=32)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\")  # Convert probabilities to binary labels\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_1, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 15ms/step - accuracy: 0.2855 - loss: 0.8857\n",
      "Epoch 2/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7322 - loss: 0.5829\n",
      "Epoch 3/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8530 - loss: 0.4488\n",
      "Epoch 4/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8986 - loss: 0.3488\n",
      "Epoch 5/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8790 - loss: 0.3452\n",
      "Epoch 6/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9023 - loss: 0.3046 \n",
      "Epoch 7/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9163 - loss: 0.2491\n",
      "Epoch 8/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8965 - loss: 0.2951\n",
      "Epoch 9/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9373 - loss: 0.1871 \n",
      "Epoch 10/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9202 - loss: 0.2272\n",
      "Epoch 11/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9118 - loss: 0.2335 \n",
      "Epoch 12/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9419 - loss: 0.1819 \n",
      "Epoch 13/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9260 - loss: 0.1977 \n",
      "Epoch 14/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9554 - loss: 0.1579 \n",
      "Epoch 15/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9303 - loss: 0.1990\n",
      "Epoch 16/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9447 - loss: 0.1764 \n",
      "Epoch 17/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9337 - loss: 0.1707 \n",
      "Epoch 18/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9352 - loss: 0.2010 \n",
      "Epoch 19/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9378 - loss: 0.1972 \n",
      "Epoch 20/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9492 - loss: 0.1946\n",
      "Epoch 21/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9650 - loss: 0.1542 \n",
      "Epoch 22/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9439 - loss: 0.1927 \n",
      "Epoch 23/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9612 - loss: 0.1619 \n",
      "Epoch 24/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9696 - loss: 0.1173\n",
      "Epoch 25/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9504 - loss: 0.1675\n",
      "Epoch 26/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9341 - loss: 0.1810\n",
      "Epoch 27/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9671 - loss: 0.1508\n",
      "Epoch 28/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9519 - loss: 0.1393\n",
      "Epoch 29/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9666 - loss: 0.1384\n",
      "Epoch 30/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9722 - loss: 0.1132\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step\n",
      "Test Accuracy: 86.08%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv1D, MaxPooling1D, Flatten, Add, Activation, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split your data into training and testing sets (replace X and y with your dataset)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the input data (optional but recommended)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_1)\n",
    "X_test = scaler.transform(X_test_1)\n",
    "\n",
    "# Reshape data to fit into a 1D CNN. New shape will be (samples, features, 1) for ResNet-like 1D convolutions.\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Define the Residual Block\n",
    "def residual_block(x, filters, kernel_size=2):\n",
    "    shortcut = x\n",
    "    \n",
    "    # First convolution\n",
    "    x = Conv1D(filters=filters, kernel_size=kernel_size, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # Second convolution\n",
    "    x = Conv1D(filters=filters, kernel_size=kernel_size, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Adding shortcut to the output of the second conv layer\n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "# Build the ResNet-like model for tabular data\n",
    "input_layer = Input(shape=(X_train.shape[1], 1))\n",
    "\n",
    "# Initial Convolution and Pooling layer\n",
    "x = Conv1D(filters=8, kernel_size=2, padding='same')(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "# First Residual Block\n",
    "x = residual_block(x, filters=8)\n",
    "\n",
    "# Second Residual Block\n",
    "x = residual_block(x, filters=8)\n",
    "x = residual_block(x, filters=8)\n",
    "\n",
    "\n",
    "# Flatten the data for the fully connected layer\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Fully connected layer\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "# Output layer for binary classification (sigmoid activation)\n",
    "output_layer = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train_1, epochs=30, batch_size=32)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test_1, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.5195 - loss: 0.6929\n",
      "Epoch 2/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8229 - loss: 0.6731 \n",
      "Epoch 3/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8660 - loss: 0.6506 \n",
      "Epoch 4/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8467 - loss: 0.6147 \n",
      "Epoch 5/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8446 - loss: 0.5594 \n",
      "Epoch 6/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8432 - loss: 0.4632 \n",
      "Epoch 7/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8120 - loss: 0.4534 \n",
      "Epoch 8/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8317 - loss: 0.4357 \n",
      "Epoch 9/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8645 - loss: 0.4076 \n",
      "Epoch 10/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8384 - loss: 0.4131\n",
      "Epoch 11/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8533 - loss: 0.4188 \n",
      "Epoch 12/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8489 - loss: 0.4199 \n",
      "Epoch 13/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8898 - loss: 0.3545 \n",
      "Epoch 14/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8953 - loss: 0.3650 \n",
      "Epoch 15/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8837 - loss: 0.3760 \n",
      "Epoch 16/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9178 - loss: 0.2942 \n",
      "Epoch 17/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8714 - loss: 0.3929\n",
      "Epoch 18/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8925 - loss: 0.3491\n",
      "Epoch 19/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8710 - loss: 0.3822\n",
      "Epoch 20/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8948 - loss: 0.3027\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 231ms/step\n",
      "Test Accuracy: 86.08%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, GRU\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split your data into training and testing sets (replace X and y with your dataset)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the input data (optional but recommended for neural networks)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_1)\n",
    "X_test = scaler.transform(X_test_1)\n",
    "\n",
    "# Reshape the data to fit into an RNN. The new shape will be (samples, timesteps, features).\n",
    "# We treat the number of features as timesteps in this case.\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Build a simple RNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Adding an RNN layer with 50 units (neurons)\n",
    "# model.add(SimpleRNN(units=50, input_shape=(X_train.shape[1], 1), activation='relu'))\n",
    "model.add(LSTM(units=50, input_shape=(X_train.shape[1], 1), activation='relu'))\n",
    "\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Output layer for binary classification (sigmoid activation)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_1, epochs=20, batch_size=32)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\")  # Convert probabilities to binary labels\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test_1, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pycaret'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Importing necessary libraries\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m setup, compare_models, tune_model, evaluate_model, save_model, load_model\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load your dataset (replace 'your_dataset.csv' with your actual dataset)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# df = pd.read_csv('your_dataset.csv')\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Setup the PyCaret environment for classification\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# In the 'target' argument, provide the column name of the target variable\u001b[39;00m\n\u001b[0;32m     10\u001b[0m clf_setup \u001b[38;5;241m=\u001b[39m setup(data\u001b[38;5;241m=\u001b[39mdf_imputed_1, target\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m, session_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m, \n\u001b[0;32m     11\u001b[0m                   normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[0;32m     12\u001b[0m                   train_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m                   silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# For automated setup\u001b[39;00m\n\u001b[0;32m     16\u001b[0m                   verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# Suppress detailed logs\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pycaret'"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from pycaret.classification import setup, compare_models, tune_model, evaluate_model, save_model, load_model\n",
    "\n",
    "# Load your dataset (replace 'your_dataset.csv' with your actual dataset)\n",
    "# df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Setup the PyCaret environment for classification\n",
    "# In the 'target' argument, provide the column name of the target variable\n",
    "clf_setup = setup(data=df_imputed_1, target='class', session_id=123, \n",
    "                  normalize=True, \n",
    "                  train_size=0.8, \n",
    "                  feature_selection=True,  # Enable feature selection\n",
    "                  remove_multicollinearity=True,  # Remove highly correlated features\n",
    "                  silent=True,  # For automated setup\n",
    "                  verbose=False)  # Suppress detailed logs\n",
    "\n",
    "# Compare all classification models and get the best one\n",
    "best_model = compare_models()\n",
    "\n",
    "# Optionally, tune the best model for better performance\n",
    "tuned_model = tune_model(best_model)\n",
    "\n",
    "# Evaluate the model (this will open an interactive window in Jupyter notebooks)\n",
    "evaluate_model(tuned_model)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = predict_model(tuned_model)\n",
    "\n",
    "# Save the model to a file\n",
    "save_model(tuned_model, 'best_classification_model')\n",
    "\n",
    "# Load the model (optional, if you want to load it later)\n",
    "# loaded_model = load_model('best_classification_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78481\n",
      "Recall: 0.75926\n",
      "Precision: 0.91111\n",
      "F1 Score: 0.82828\n",
      "Cohen's Kappa: 0.54644\n",
      "Confusion Matrix:\n",
      "[[21  4]\n",
      " [13 41]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier,AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf1 = AdaBoostClassifier()\n",
    "clf2 = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[\n",
    "        ('lr', clf1), ('rf', clf2)], voting='hard')\n",
    "eclf1 = eclf1.fit(X_train_1, y_train_1)\n",
    "\n",
    "y_pred_1 = eclf1.predict(X_test_1)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test_1, y_pred_1)\n",
    "recall = recall_score(y_test_1, y_pred_1)\n",
    "precision = precision_score(y_test_1, y_pred_1)\n",
    "f1 = f1_score(y_test_1, y_pred_1)\n",
    "kappa = cohen_kappa_score(y_test_1, y_pred_1)\n",
    "conf_matrix = confusion_matrix(y_test_1, y_pred_1)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"F1 Score: {f1:.5f}\")\n",
    "print(f\"Cohen's Kappa: {kappa:.5f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94937\n",
      "Recall: 0.96296\n",
      "Precision: 0.96296\n",
      "F1 Score: 0.96\n",
      "Cohen's Kappa: 0.88\n",
      "Confusion Matrix:\n",
      "[[23  2]\n",
      " [ 2 52]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix, cohen_kappa_score, f1_score\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "# # Initialize XGBoost classifier\n",
    "# xgb_model_1 = RandomForestClassifier()\n",
    "\n",
    "# # Fit the model\n",
    "# xgb_model_1.fit(X_train_1, y_train_1)\n",
    "\n",
    "# # Predict using the same selected features\n",
    "# y_pred_1 = xgb_model_1.predict(X_test_1)\n",
    "\n",
    "# # Calculate evaluation metrics\n",
    "# accuracy = accuracy_score(y_test_1, y_pred_1)\n",
    "# recall = recall_score(y_test_1, y_pred_1)\n",
    "# precision = precision_score(y_test_1, y_pred_1)\n",
    "# f1 = f1_score(y_test_1, y_pred_1)\n",
    "# kappa = cohen_kappa_score(y_test_1, y_pred_1)\n",
    "# conf_matrix = confusion_matrix(y_test_1, y_pred_1)\n",
    "\n",
    "# # Display the results\n",
    "# print(f\"Accuracy: {accuracy:.5f}\")\n",
    "# print(f\"Recall: {recall:.5f}\")\n",
    "# print(f\"Precision: {precision:.5f}\")\n",
    "# print(f\"F1 Score: {f1:.2f}\")\n",
    "# print(f\"Cohen's Kappa: {kappa:.2f}\")\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix, cohen_kappa_score, f1_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # Initialize RandomForest classifier\n",
    "# rf_model_2 = RandomForestClassifier()\n",
    "\n",
    "# # Fit the model\n",
    "# rf_model_2.fit(X_train_2, y_train_2)\n",
    "\n",
    "# # Predict using the same selected features\n",
    "# y_pred_2 = rf_model_2.predict(X_test_2)\n",
    "\n",
    "# # Calculate evaluation metrics\n",
    "# accuracy = accuracy_score(y_test_2, y_pred_2)\n",
    "# recall = recall_score(y_test_2, y_pred_2)\n",
    "# precision = precision_score(y_test_2, y_pred_2)\n",
    "# f1 = f1_score(y_test_2, y_pred_2)\n",
    "# kappa = cohen_kappa_score(y_test_2, y_pred_2)\n",
    "# conf_matrix = confusion_matrix(y_test_2, y_pred_2)\n",
    "\n",
    "# # Display the results\n",
    "# print(f\"Accuracy: {accuracy:.5f}\")\n",
    "# print(f\"Recall: {recall:.5f}\")\n",
    "# print(f\"Precision: {precision:.5f}\")\n",
    "# print(f\"F1 Score: {f1:.2f}\")\n",
    "# print(f\"Cohen's Kappa: {kappa:.2f}\")\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96203\n",
      "Recall: 0.96296\n",
      "Precision: 0.98113\n",
      "F1 Score: 0.97\n",
      "Cohen's Kappa: 0.91\n",
      "Confusion Matrix:\n",
      "[[24  1]\n",
      " [ 2 52]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix, cohen_kappa_score, f1_score\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# # Initialize XGBoost classifier\n",
    "# xgb_model_2 = RandomForestClassifier()\n",
    "\n",
    "# # Fit the model\n",
    "# xgb_model_2.fit(X_train_2, y_train_2)\n",
    "\n",
    "# # Predict using the same selected features\n",
    "# y_pred_2 = xgb_model_2.predict(X_test_2)\n",
    "\n",
    "# # Calculate evaluation metrics\n",
    "# accuracy = accuracy_score(y_test_2, y_pred_2)\n",
    "# recall = recall_score(y_test_2, y_pred_2)\n",
    "# precision = precision_score(y_test_2, y_pred_2)\n",
    "# f1 = f1_score(y_test_2, y_pred_2)\n",
    "# kappa = cohen_kappa_score(y_test_2, y_pred_2)\n",
    "# conf_matrix = confusion_matrix(y_test_2, y_pred_2)\n",
    "\n",
    "# # Display the results\n",
    "# print(f\"Accuracy: {accuracy:.5f}\")\n",
    "# print(f\"Recall: {recall:.5f}\")\n",
    "# print(f\"Precision: {precision:.5f}\")\n",
    "# print(f\"F1 Score: {f1:.2f}\")\n",
    "# print(f\"Cohen's Kappa: {kappa:.2f}\")\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94937\n",
      "Recall: 0.96296\n",
      "Precision: 0.96296\n",
      "F1 Score: 0.96\n",
      "Cohen's Kappa: 0.88\n",
      "Confusion Matrix:\n",
      "[[23  2]\n",
      " [ 2 52]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix, cohen_kappa_score, f1_score\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "# # Initialize XGBoost classifier\n",
    "# xgb_model_3 = RandomForestClassifier()\n",
    "\n",
    "# # Fit the model\n",
    "# xgb_model_3.fit(X_train_3, y_train_3)\n",
    "\n",
    "# # Predict using the same selected features\n",
    "# y_pred_3 = xgb_model_3.predict(X_test_3)\n",
    "\n",
    "# # Calculate evaluation metrics\n",
    "# accuracy = accuracy_score(y_test_3, y_pred_3)\n",
    "# recall = recall_score(y_test_3, y_pred_3)\n",
    "# precision = precision_score(y_test_3, y_pred_3)\n",
    "# f1 = f1_score(y_test_3, y_pred_3)\n",
    "# kappa = cohen_kappa_score(y_test_3, y_pred_3)\n",
    "# conf_matrix = confusion_matrix(y_test_3, y_pred_3)\n",
    "\n",
    "# # Display the results\n",
    "# print(f\"Accuracy: {accuracy:.5f}\")\n",
    "# print(f\"Recall: {recall:.5f}\")\n",
    "# print(f\"Precision: {precision:.5f}\")\n",
    "# print(f\"F1 Score: {f1:.2f}\")\n",
    "# print(f\"Cohen's Kappa: {kappa:.2f}\")\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96203\n",
      "Recall: 0.96296\n",
      "Precision: 0.98113\n",
      "F1 Score: 0.97\n",
      "Cohen's Kappa: 0.91\n",
      "Confusion Matrix:\n",
      "[[24  1]\n",
      " [ 2 52]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix, cohen_kappa_score, f1_score\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "# # Initialize XGBoost classifier\n",
    "# xgb_model_4 = RandomForestClassifier()\n",
    "\n",
    "# # Fit the model\n",
    "# xgb_model_4.fit(X_train_4, y_train_4)\n",
    "\n",
    "# # Predict using the same selected features\n",
    "# y_pred_4 = xgb_model_4.predict(X_test_4)\n",
    "\n",
    "# # Calculate evaluation metrics\n",
    "# accuracy = accuracy_score(y_test_4, y_pred_4)\n",
    "# recall = recall_score(y_test_4, y_pred_4)\n",
    "# precision = precision_score(y_test_4, y_pred_4)\n",
    "# f1 = f1_score(y_test_4, y_pred_4)\n",
    "# kappa = cohen_kappa_score(y_test_4, y_pred_4)\n",
    "# conf_matrix = confusion_matrix(y_test_4, y_pred_4)\n",
    "\n",
    "# # Display the results\n",
    "# print(f\"Accuracy: {accuracy:.5f}\")\n",
    "# print(f\"Recall: {recall:.5f}\")\n",
    "# print(f\"Precision: {precision:.5f}\")\n",
    "# print(f\"F1 Score: {f1:.2f}\")\n",
    "# print(f\"Cohen's Kappa: {kappa:.2f}\")\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96203\n",
      "Recall: 0.96296\n",
      "Precision: 0.98113\n",
      "F1 Score: 0.97\n",
      "Cohen's Kappa: 0.91\n",
      "Confusion Matrix:\n",
      "[[24  1]\n",
      " [ 2 52]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix, cohen_kappa_score, f1_score\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "# # Initialize XGBoost classifier\n",
    "# xgb_model_5 = RandomForestClassifier()\n",
    "\n",
    "# # Fit the model\n",
    "# xgb_model_5.fit(X_train_5, y_train_5)\n",
    "\n",
    "# # Predict using the same selected features\n",
    "# y_pred_5 = xgb_model_5.predict(X_test_5)\n",
    "\n",
    "# # Calculate evaluation metrics\n",
    "# accuracy = accuracy_score(y_test_5, y_pred_5)\n",
    "# recall = recall_score(y_test_5, y_pred_5)\n",
    "# precision = precision_score(y_test_5, y_pred_5)\n",
    "# f1 = f1_score(y_test_5, y_pred_5)\n",
    "# kappa = cohen_kappa_score(y_test_5, y_pred_5)\n",
    "# conf_matrix = confusion_matrix(y_test_5, y_pred_5)\n",
    "\n",
    "# # Display the results\n",
    "# print(f\"Accuracy: {accuracy:.5f}\")\n",
    "# print(f\"Recall: {recall:.5f}\")\n",
    "# print(f\"Precision: {precision:.5f}\")\n",
    "# print(f\"F1 Score: {f1:.2f}\")\n",
    "# print(f\"Cohen's Kappa: {kappa:.2f}\")\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96203\n",
      "Recall: 0.96296\n",
      "Precision: 0.98113\n",
      "F1 Score: 0.97\n",
      "Cohen's Kappa: 0.91\n",
      "Confusion Matrix:\n",
      "[[24  1]\n",
      " [ 2 52]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix, cohen_kappa_score, f1_score\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "# # Initialize XGBoost classifier\n",
    "# xgb_model_6 = RandomForestClassifier()\n",
    "\n",
    "# # Fit the model\n",
    "# xgb_model_6.fit(X_train_6, y_train_6)\n",
    "\n",
    "# # Predict using the same selected features\n",
    "# y_pred_6 = xgb_model_6.predict(X_test_6)\n",
    "\n",
    "# # Calculate evaluation metrics\n",
    "# accuracy = accuracy_score(y_test_6, y_pred_6)\n",
    "# recall = recall_score(y_test_6, y_pred_6)\n",
    "# precision = precision_score(y_test_6, y_pred_6)\n",
    "# f1 = f1_score(y_test_6, y_pred_6)\n",
    "# kappa = cohen_kappa_score(y_test_6, y_pred_6)\n",
    "# conf_matrix = confusion_matrix(y_test_6, y_pred_6)\n",
    "\n",
    "# # Display the results\n",
    "# print(f\"Accuracy: {accuracy:.5f}\")\n",
    "# print(f\"Recall: {recall:.5f}\")\n",
    "# print(f\"Precision: {precision:.5f}\")\n",
    "# print(f\"F1 Score: {f1:.2f}\")\n",
    "# print(f\"Cohen's Kappa: {kappa:.2f}\")\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Predict probabilities for the training set from both models\n",
    "# prob_model_1_train = xgb_model_1.predict_proba(X_train_1)\n",
    "# prob_model_2_train = xgb_model_2.predict_proba(X_train_2)\n",
    "\n",
    "# # Combine the probabilities for both classes (4 features: 2 from each model)\n",
    "# X_train_ann = np.hstack((prob_model_1_train, prob_model_2_train))\n",
    "\n",
    "# # Similarly, get the true labels\n",
    "# y_train_ann = y_train_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob_model_1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob_model_2_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "\n",
    "# # Define the ANN model\n",
    "# ann_model = Sequential()\n",
    "\n",
    "# # Input layer (4 inputs from combined probabilities) and hidden layer\n",
    "# ann_model.add(Dense(8, input_dim=4, activation='relu'))  # 4 input features (2 for each class from both models)\n",
    "\n",
    "# # Hidden layer (adjust neurons as needed)\n",
    "# ann_model.add(Dense(4, activation='relu'))\n",
    "\n",
    "# # Output layer (binary classification)\n",
    "# ann_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# # Compile the model\n",
    "# ann_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train the model on the combined probability inputs\n",
    "# ann_model.fit(X_train_ann, y_train_ann, epochs=10, batch_size=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict probabilities for the test set from both models\n",
    "# prob_model_1_test = xgb_model_1.predict_proba(X_test_1)\n",
    "# prob_model_2_test = xgb_model_2.predict_proba(X_test_1)\n",
    "\n",
    "# # Combine the probabilities for test set\n",
    "# X_test_ann = np.hstack((prob_model_1_test, prob_model_2_test))\n",
    "\n",
    "# # Use the trained ANN model to predict the classes on the test set\n",
    "# y_pred_ann = (ann_model.predict(X_test_ann) > 0.5).astype(int)\n",
    "\n",
    "# # Calculate the accuracy\n",
    "# accuracy = accuracy_score(y_test_1, y_pred_ann)\n",
    "\n",
    "# # Display the accuracy\n",
    "# print(f\"ANN Model Accuracy: {accuracy:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96203\n",
      "Recall: 0.96296\n",
      "Precision: 0.98113\n",
      "F1 Score: 0.97196\n",
      "Cohen's Kappa: 0.91316\n",
      "Confusion Matrix:\n",
      "[[24  1]\n",
      " [ 2 52]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, cohen_kappa_score\n",
    "\n",
    "# Predict probabilities for all test sets\n",
    "prob_model_1_test = xgb_model_1.predict_proba(X_test_1)\n",
    "prob_model_2_test = xgb_model_2.predict_proba(X_test_2)\n",
    "prob_model_3_test = xgb_model_3.predict_proba(X_test_3)\n",
    "prob_model_4_test = xgb_model_4.predict_proba(X_test_4)\n",
    "prob_model_5_test = xgb_model_5.predict_proba(X_test_5)\n",
    "prob_model_6_test = xgb_model_6.predict_proba(X_test_6)\n",
    "\n",
    "# Get the probabilities for class 1 (positive class) from all models\n",
    "probs_class_1 = np.vstack([\n",
    "    prob_model_1_test[:, 1],  # Class 1 probability for model 1\n",
    "    prob_model_2_test[:, 1],  # Class 1 probability for model 2\n",
    "    prob_model_3_test[:, 1],  # Class 1 probability for model 3\n",
    "    prob_model_4_test[:, 1],  # Class 1 probability for model 4\n",
    "    prob_model_5_test[:, 1],  # Class 1 probability for model 5\n",
    "    prob_model_6_test[:, 1]   # Class 1 probability for model 6\n",
    "])\n",
    "\n",
    "# Perform voting (count how many models predict class 1)\n",
    "votes_class_1 = np.sum(probs_class_1 > 0.5, axis=0)  # Count the number of models predicting class 1\n",
    "\n",
    "# Majority voting: if 3 or more models predict class 1, the final prediction is class 1\n",
    "y_pred_voted = (votes_class_1 >= 3).astype(int)\n",
    "\n",
    "# True labels (assuming you have the labels for the test set)\n",
    "# Replace y_test with the actual labels for your data\n",
    "y_test = y_test_1  # or the combined test labels\n",
    "\n",
    "# Calculate accuracy and other metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_voted)\n",
    "recall = recall_score(y_test, y_pred_voted)\n",
    "precision = precision_score(y_test, y_pred_voted)\n",
    "f1 = f1_score(y_test, y_pred_voted)\n",
    "kappa = cohen_kappa_score(y_test, y_pred_voted)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_voted)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"F1 Score: {f1:.5f}\")\n",
    "print(f\"Cohen's Kappa: {kappa:.5f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Model Accuracy: 0.94937\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Predict probabilities for both models on the test set\n",
    "# prob_model_1_test = xgb_model_1.predict_proba(X_test_1)\n",
    "# prob_model_2_test = xgb_model_2.predict_proba(X_test_2)\n",
    "# prob_model_3_test = xgb_model_3.predict_proba(X_test_3)\n",
    "# prob_model_4_test = xgb_model_4.predict_proba(X_test_4)\n",
    "# prob_model_5_test = xgb_model_5.predict_proba(X_test_5)\n",
    "# prob_model_6_test = xgb_model_6.predict_proba(X_test_6)\n",
    "\n",
    "\n",
    "# # Sum the probabilities from both models\n",
    "# combined_prob_test = np.add(prob_model_1_test, prob_model_2_test)\n",
    "\n",
    "# # Predict the class with the highest combined probability\n",
    "# y_pred_combined = np.argmax(combined_prob_test, axis=1)\n",
    "\n",
    "# # Calculate accuracy\n",
    "# accuracy = accuracy_score(y_test_1, y_pred_combined)\n",
    "\n",
    "# # Display the accuracy\n",
    "# print(f\"Combined Model Accuracy: {accuracy:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.84378099e-01, 1.56219145e-02],\n",
       "       [1.85494423e-02, 9.81450558e-01],\n",
       "       [9.99695301e-01, 3.04717280e-04],\n",
       "       [1.89132094e-02, 9.81086791e-01],\n",
       "       [3.32885981e-03, 9.96671140e-01],\n",
       "       [9.99726951e-01, 2.73036188e-04],\n",
       "       [3.01241875e-04, 9.99698758e-01],\n",
       "       [9.96275008e-01, 3.72498110e-03],\n",
       "       [9.99452174e-01, 5.47835545e-04],\n",
       "       [6.32089376e-03, 9.93679106e-01],\n",
       "       [9.17315483e-04, 9.99082685e-01],\n",
       "       [9.99397516e-01, 6.02512038e-04],\n",
       "       [9.97153282e-01, 2.84669315e-03],\n",
       "       [8.65811110e-03, 9.91341889e-01],\n",
       "       [8.73956859e-01, 1.26043156e-01],\n",
       "       [5.61475754e-05, 9.99943852e-01],\n",
       "       [3.87692451e-02, 9.61230755e-01],\n",
       "       [9.99338925e-01, 6.61073427e-04],\n",
       "       [9.98216629e-01, 1.78335793e-03],\n",
       "       [9.99708533e-01, 2.91469536e-04],\n",
       "       [2.61767507e-02, 9.73823249e-01],\n",
       "       [3.25051248e-01, 6.74948752e-01],\n",
       "       [1.21301413e-03, 9.98786986e-01],\n",
       "       [2.03496218e-02, 9.79650378e-01],\n",
       "       [2.41816044e-03, 9.97581840e-01],\n",
       "       [4.82708216e-03, 9.95172918e-01],\n",
       "       [7.18998909e-03, 9.92810011e-01],\n",
       "       [4.39053774e-03, 9.95609462e-01],\n",
       "       [6.02304935e-03, 9.93976951e-01],\n",
       "       [8.79764557e-05, 9.99912024e-01],\n",
       "       [9.99137282e-01, 8.62710120e-04],\n",
       "       [9.40501690e-04, 9.99059498e-01],\n",
       "       [9.99371529e-01, 6.28443435e-04],\n",
       "       [1.86514854e-03, 9.98134851e-01],\n",
       "       [6.72221184e-04, 9.99327779e-01],\n",
       "       [3.51817012e-02, 9.64818299e-01],\n",
       "       [3.81523371e-03, 9.96184766e-01],\n",
       "       [2.16108561e-03, 9.97838914e-01],\n",
       "       [5.95283508e-03, 9.94047165e-01],\n",
       "       [1.14500523e-03, 9.98854995e-01],\n",
       "       [1.17784739e-03, 9.98822153e-01],\n",
       "       [1.10864639e-04, 9.99889135e-01],\n",
       "       [9.99137282e-01, 8.62710120e-04],\n",
       "       [6.62380457e-03, 9.93376195e-01],\n",
       "       [4.39929366e-02, 9.56007063e-01],\n",
       "       [1.06602907e-03, 9.98933971e-01],\n",
       "       [8.12947750e-03, 9.91870522e-01],\n",
       "       [9.99802828e-01, 1.97194051e-04],\n",
       "       [9.97422099e-01, 2.57789111e-03],\n",
       "       [1.25336647e-03, 9.98746634e-01],\n",
       "       [9.82319653e-01, 1.76803526e-02],\n",
       "       [9.99807417e-01, 1.92561012e-04],\n",
       "       [1.64180994e-03, 9.98358190e-01],\n",
       "       [1.65569782e-03, 9.98344302e-01],\n",
       "       [8.98995340e-01, 1.01004675e-01],\n",
       "       [4.86060381e-02, 9.51393962e-01],\n",
       "       [9.78748143e-01, 2.12518349e-02],\n",
       "       [5.30849099e-02, 9.46915090e-01],\n",
       "       [9.99752760e-01, 2.47254327e-04],\n",
       "       [1.81692839e-03, 9.98183072e-01],\n",
       "       [2.26079226e-02, 9.77392077e-01],\n",
       "       [9.89334881e-01, 1.06651373e-02],\n",
       "       [1.10864639e-04, 9.99889135e-01],\n",
       "       [5.63490391e-03, 9.94365096e-01],\n",
       "       [1.07385874e-01, 8.92614126e-01],\n",
       "       [1.26785040e-03, 9.98732150e-01],\n",
       "       [9.81577635e-01, 1.84223354e-02],\n",
       "       [4.14669514e-04, 9.99585330e-01],\n",
       "       [9.98189569e-01, 1.81043590e-03],\n",
       "       [4.68313694e-03, 9.95316863e-01],\n",
       "       [1.18070841e-03, 9.98819292e-01],\n",
       "       [1.35536015e-01, 8.64463985e-01],\n",
       "       [9.99593496e-01, 4.06519044e-04],\n",
       "       [2.48479247e-02, 9.75152075e-01],\n",
       "       [1.44654512e-03, 9.98553455e-01],\n",
       "       [8.88430953e-01, 1.11569032e-01],\n",
       "       [8.78989697e-04, 9.99121010e-01],\n",
       "       [8.96614790e-03, 9.91033852e-01],\n",
       "       [3.85308266e-03, 9.96146917e-01]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_model_1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.7494936e-01, 2.5050610e-02],\n",
       "       [5.8109343e-02, 9.4189066e-01],\n",
       "       [9.9956602e-01, 4.3400822e-04],\n",
       "       [5.9127808e-04, 9.9940872e-01],\n",
       "       [4.4577718e-03, 9.9554223e-01],\n",
       "       [9.9926358e-01, 7.3641521e-04],\n",
       "       [2.0319223e-04, 9.9979681e-01],\n",
       "       [9.9943835e-01, 5.6164118e-04],\n",
       "       [9.9941945e-01, 5.8052863e-04],\n",
       "       [4.5448542e-03, 9.9545515e-01],\n",
       "       [9.9891424e-04, 9.9900109e-01],\n",
       "       [9.9628550e-01, 3.7145182e-03],\n",
       "       [9.9960577e-01, 3.9421261e-04],\n",
       "       [4.5821667e-03, 9.9541783e-01],\n",
       "       [8.9666307e-01, 1.0333694e-01],\n",
       "       [1.6021729e-04, 9.9983978e-01],\n",
       "       [1.8241823e-02, 9.8175818e-01],\n",
       "       [9.9916446e-01, 8.3556224e-04],\n",
       "       [9.9932981e-01, 6.7021797e-04],\n",
       "       [9.9946260e-01, 5.3742004e-04],\n",
       "       [2.0649844e-01, 7.9350156e-01],\n",
       "       [5.5626631e-02, 9.4437337e-01],\n",
       "       [3.2126904e-04, 9.9967873e-01],\n",
       "       [4.7194362e-03, 9.9528056e-01],\n",
       "       [3.7539005e-04, 9.9962461e-01],\n",
       "       [6.0131550e-03, 9.9398685e-01],\n",
       "       [2.7536213e-02, 9.7246379e-01],\n",
       "       [9.5218420e-04, 9.9904782e-01],\n",
       "       [2.6890039e-03, 9.9731100e-01],\n",
       "       [3.0326843e-04, 9.9969673e-01],\n",
       "       [9.9974263e-01, 2.5736075e-04],\n",
       "       [5.6022406e-04, 9.9943978e-01],\n",
       "       [9.9944830e-01, 5.5172906e-04],\n",
       "       [2.6248693e-03, 9.9737513e-01],\n",
       "       [8.3613396e-04, 9.9916387e-01],\n",
       "       [5.4503083e-03, 9.9454969e-01],\n",
       "       [5.3328276e-04, 9.9946672e-01],\n",
       "       [7.6999664e-03, 9.9230003e-01],\n",
       "       [6.9550872e-03, 9.9304491e-01],\n",
       "       [1.1389256e-03, 9.9886107e-01],\n",
       "       [1.6728044e-03, 9.9832720e-01],\n",
       "       [1.7225742e-04, 9.9982774e-01],\n",
       "       [9.9974263e-01, 2.5736075e-04],\n",
       "       [1.6145527e-02, 9.8385447e-01],\n",
       "       [6.3777566e-03, 9.9362224e-01],\n",
       "       [2.4136305e-03, 9.9758637e-01],\n",
       "       [1.0006368e-02, 9.8999363e-01],\n",
       "       [9.9946260e-01, 5.3742004e-04],\n",
       "       [9.9847531e-01, 1.5247138e-03],\n",
       "       [1.2900829e-03, 9.9870992e-01],\n",
       "       [9.8087478e-01, 1.9125203e-02],\n",
       "       [9.9974239e-01, 2.5760356e-04],\n",
       "       [1.6745925e-03, 9.9832541e-01],\n",
       "       [6.6417456e-04, 9.9933583e-01],\n",
       "       [9.7085154e-01, 2.9148461e-02],\n",
       "       [4.7813177e-02, 9.5218682e-01],\n",
       "       [9.8815030e-01, 1.1849709e-02],\n",
       "       [2.1366477e-03, 9.9786335e-01],\n",
       "       [9.9940401e-01, 5.9598475e-04],\n",
       "       [2.8954148e-03, 9.9710459e-01],\n",
       "       [1.2745321e-02, 9.8725468e-01],\n",
       "       [9.7379363e-01, 2.6206404e-02],\n",
       "       [1.8638372e-04, 9.9981362e-01],\n",
       "       [9.3582273e-03, 9.9064177e-01],\n",
       "       [5.4310620e-02, 9.4568938e-01],\n",
       "       [3.6454201e-04, 9.9963546e-01],\n",
       "       [9.7356600e-01, 2.6434027e-02],\n",
       "       [6.4045191e-04, 9.9935955e-01],\n",
       "       [9.9963564e-01, 3.6436369e-04],\n",
       "       [6.0856342e-04, 9.9939144e-01],\n",
       "       [1.3355017e-03, 9.9866450e-01],\n",
       "       [8.7378359e-01, 1.2621641e-01],\n",
       "       [9.9930894e-01, 6.9103821e-04],\n",
       "       [1.1405945e-03, 9.9885941e-01],\n",
       "       [1.0669827e-03, 9.9893302e-01],\n",
       "       [9.7023654e-01, 2.9763473e-02],\n",
       "       [4.9698353e-04, 9.9950302e-01],\n",
       "       [5.8555543e-02, 9.4144446e-01],\n",
       "       [2.0312667e-03, 9.9796873e-01]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_model_2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
       "       0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6430 - loss: 0.6454 - val_accuracy: 0.6555 - val_loss: 0.6292\n",
      "Epoch 2/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7808 - loss: 0.5887 - val_accuracy: 0.7983 - val_loss: 0.5692\n",
      "Epoch 3/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8942 - loss: 0.4984 - val_accuracy: 0.8487 - val_loss: 0.5102\n",
      "Epoch 4/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8833 - loss: 0.4531 - val_accuracy: 0.8739 - val_loss: 0.4501\n",
      "Epoch 5/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8920 - loss: 0.3967 - val_accuracy: 0.8824 - val_loss: 0.3958\n",
      "Epoch 6/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9506 - loss: 0.3155 - val_accuracy: 0.8824 - val_loss: 0.3564\n",
      "Epoch 7/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9180 - loss: 0.2776 - val_accuracy: 0.8908 - val_loss: 0.3303\n",
      "Epoch 8/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9043 - loss: 0.2743 - val_accuracy: 0.8908 - val_loss: 0.3080\n",
      "Epoch 9/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9258 - loss: 0.2495 - val_accuracy: 0.8824 - val_loss: 0.2971\n",
      "Epoch 10/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9425 - loss: 0.2072 - val_accuracy: 0.8824 - val_loss: 0.2930\n",
      "Epoch 11/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9229 - loss: 0.2172 - val_accuracy: 0.8908 - val_loss: 0.2876\n",
      "Epoch 12/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9475 - loss: 0.1739 - val_accuracy: 0.8824 - val_loss: 0.2840\n",
      "Epoch 13/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9266 - loss: 0.1862 - val_accuracy: 0.8824 - val_loss: 0.2816\n",
      "Epoch 14/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9433 - loss: 0.1891 - val_accuracy: 0.8992 - val_loss: 0.2830\n",
      "Epoch 15/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9415 - loss: 0.1684 - val_accuracy: 0.8992 - val_loss: 0.2780\n",
      "Epoch 16/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9488 - loss: 0.1421 - val_accuracy: 0.8992 - val_loss: 0.2817\n",
      "Epoch 17/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9368 - loss: 0.1681 - val_accuracy: 0.8992 - val_loss: 0.2821\n",
      "Epoch 18/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9512 - loss: 0.1532 - val_accuracy: 0.8908 - val_loss: 0.2850\n",
      "Epoch 19/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9375 - loss: 0.1695 - val_accuracy: 0.8908 - val_loss: 0.2840\n",
      "Epoch 20/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9572 - loss: 0.1706 - val_accuracy: 0.8908 - val_loss: 0.2838\n",
      "Epoch 21/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.1932 - val_accuracy: 0.8908 - val_loss: 0.2859\n",
      "Epoch 22/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9571 - loss: 0.1383 - val_accuracy: 0.8908 - val_loss: 0.2868\n",
      "Epoch 23/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9292 - loss: 0.2061 - val_accuracy: 0.8992 - val_loss: 0.2880\n",
      "Epoch 24/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9354 - loss: 0.1705 - val_accuracy: 0.8992 - val_loss: 0.2919\n",
      "Epoch 25/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9342 - loss: 0.1517 - val_accuracy: 0.8992 - val_loss: 0.2906\n",
      "Epoch 26/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9520 - loss: 0.1571 - val_accuracy: 0.8992 - val_loss: 0.2915\n",
      "Epoch 27/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9606 - loss: 0.1337 - val_accuracy: 0.8992 - val_loss: 0.2943\n",
      "Epoch 28/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9641 - loss: 0.1083 - val_accuracy: 0.8992 - val_loss: 0.2967\n",
      "Epoch 29/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9558 - loss: 0.1284 - val_accuracy: 0.8992 - val_loss: 0.2950\n",
      "Epoch 30/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9418 - loss: 0.1655 - val_accuracy: 0.8992 - val_loss: 0.2979\n",
      "Epoch 31/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9717 - loss: 0.1016 - val_accuracy: 0.8908 - val_loss: 0.3038\n",
      "Epoch 32/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9660 - loss: 0.1138 - val_accuracy: 0.8992 - val_loss: 0.2995\n",
      "Epoch 33/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9720 - loss: 0.1149 - val_accuracy: 0.8992 - val_loss: 0.3038\n",
      "Epoch 34/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9528 - loss: 0.1318 - val_accuracy: 0.8992 - val_loss: 0.3035\n",
      "Epoch 35/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9570 - loss: 0.1339 - val_accuracy: 0.8908 - val_loss: 0.3048\n",
      "Epoch 36/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9471 - loss: 0.1313 - val_accuracy: 0.8908 - val_loss: 0.3095\n",
      "Epoch 37/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9591 - loss: 0.1146 - val_accuracy: 0.8908 - val_loss: 0.3113\n",
      "Epoch 38/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9451 - loss: 0.1645 - val_accuracy: 0.8908 - val_loss: 0.3082\n",
      "Epoch 39/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9517 - loss: 0.1234 - val_accuracy: 0.8908 - val_loss: 0.3137\n",
      "Epoch 40/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9684 - loss: 0.1007 - val_accuracy: 0.8908 - val_loss: 0.3096\n",
      "Epoch 41/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9666 - loss: 0.1086 - val_accuracy: 0.8908 - val_loss: 0.3146\n",
      "Epoch 42/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9480 - loss: 0.1847 - val_accuracy: 0.8908 - val_loss: 0.3129\n",
      "Epoch 43/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9543 - loss: 0.1110 - val_accuracy: 0.8908 - val_loss: 0.3192\n",
      "Epoch 44/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9730 - loss: 0.0917 - val_accuracy: 0.8908 - val_loss: 0.3152\n",
      "Epoch 45/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9567 - loss: 0.1097 - val_accuracy: 0.8908 - val_loss: 0.3206\n",
      "Epoch 46/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9643 - loss: 0.1095 - val_accuracy: 0.8908 - val_loss: 0.3161\n",
      "Epoch 47/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9596 - loss: 0.1207 - val_accuracy: 0.8908 - val_loss: 0.3185\n",
      "Epoch 48/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9590 - loss: 0.1019 - val_accuracy: 0.8908 - val_loss: 0.3216\n",
      "Epoch 49/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9537 - loss: 0.1294 - val_accuracy: 0.8908 - val_loss: 0.3249\n",
      "Epoch 50/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9506 - loss: 0.1765 - val_accuracy: 0.8908 - val_loss: 0.3263\n",
      "Epoch 51/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9495 - loss: 0.1344 - val_accuracy: 0.8908 - val_loss: 0.3259\n",
      "Epoch 52/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9676 - loss: 0.1022 - val_accuracy: 0.8908 - val_loss: 0.3284\n",
      "Epoch 53/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9701 - loss: 0.1049 - val_accuracy: 0.8824 - val_loss: 0.3335\n",
      "Epoch 54/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9586 - loss: 0.1148 - val_accuracy: 0.8908 - val_loss: 0.3353\n",
      "Epoch 55/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9731 - loss: 0.0993 - val_accuracy: 0.8908 - val_loss: 0.3323\n",
      "Epoch 56/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9519 - loss: 0.1528 - val_accuracy: 0.8824 - val_loss: 0.3411\n",
      "Epoch 57/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9770 - loss: 0.0821 - val_accuracy: 0.8824 - val_loss: 0.3404\n",
      "Epoch 58/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9397 - loss: 0.1242 - val_accuracy: 0.8824 - val_loss: 0.3433\n",
      "Epoch 59/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9705 - loss: 0.1181 - val_accuracy: 0.8824 - val_loss: 0.3433\n",
      "Epoch 60/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9569 - loss: 0.0975 - val_accuracy: 0.8908 - val_loss: 0.3432\n",
      "Epoch 61/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9564 - loss: 0.1056 - val_accuracy: 0.8824 - val_loss: 0.3507\n",
      "Epoch 62/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9740 - loss: 0.1453 - val_accuracy: 0.8824 - val_loss: 0.3508\n",
      "Epoch 63/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9692 - loss: 0.0833 - val_accuracy: 0.8908 - val_loss: 0.3481\n",
      "Epoch 64/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9595 - loss: 0.0943 - val_accuracy: 0.8824 - val_loss: 0.3536\n",
      "Epoch 65/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9721 - loss: 0.0833 - val_accuracy: 0.8824 - val_loss: 0.3547\n",
      "Epoch 66/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9636 - loss: 0.1142 - val_accuracy: 0.8824 - val_loss: 0.3577\n",
      "Epoch 67/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9835 - loss: 0.0684 - val_accuracy: 0.8908 - val_loss: 0.3590\n",
      "Epoch 68/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9668 - loss: 0.1011 - val_accuracy: 0.8824 - val_loss: 0.3557\n",
      "Epoch 69/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9687 - loss: 0.0896 - val_accuracy: 0.8739 - val_loss: 0.3570\n",
      "Epoch 70/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9662 - loss: 0.0980 - val_accuracy: 0.8739 - val_loss: 0.3631\n",
      "Epoch 71/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9572 - loss: 0.1394 - val_accuracy: 0.8739 - val_loss: 0.3609\n",
      "Epoch 72/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9627 - loss: 0.1191 - val_accuracy: 0.8739 - val_loss: 0.3639\n",
      "Epoch 73/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9861 - loss: 0.0651 - val_accuracy: 0.8824 - val_loss: 0.3637\n",
      "Epoch 74/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9628 - loss: 0.1080 - val_accuracy: 0.8739 - val_loss: 0.3645\n",
      "Epoch 75/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9798 - loss: 0.0843 - val_accuracy: 0.8824 - val_loss: 0.3740\n",
      "Epoch 76/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9789 - loss: 0.0595 - val_accuracy: 0.8739 - val_loss: 0.3627\n",
      "Epoch 77/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9736 - loss: 0.0920 - val_accuracy: 0.8739 - val_loss: 0.3694\n",
      "Epoch 78/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9625 - loss: 0.0978 - val_accuracy: 0.8739 - val_loss: 0.3740\n",
      "Epoch 79/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9892 - loss: 0.0628 - val_accuracy: 0.8739 - val_loss: 0.3746\n",
      "Epoch 80/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9741 - loss: 0.0803 - val_accuracy: 0.8739 - val_loss: 0.3759\n",
      "Epoch 81/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9675 - loss: 0.0830 - val_accuracy: 0.8824 - val_loss: 0.3769\n",
      "Epoch 82/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9559 - loss: 0.1520 - val_accuracy: 0.8739 - val_loss: 0.3772\n",
      "Epoch 83/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9734 - loss: 0.0848 - val_accuracy: 0.8739 - val_loss: 0.3838\n",
      "Epoch 84/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9829 - loss: 0.0704 - val_accuracy: 0.8824 - val_loss: 0.3880\n",
      "Epoch 85/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9863 - loss: 0.0742 - val_accuracy: 0.8824 - val_loss: 0.3841\n",
      "Epoch 86/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9839 - loss: 0.0733 - val_accuracy: 0.8824 - val_loss: 0.3910\n",
      "Epoch 87/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9797 - loss: 0.0793 - val_accuracy: 0.8824 - val_loss: 0.3869\n",
      "Epoch 88/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9862 - loss: 0.0530 - val_accuracy: 0.8908 - val_loss: 0.3952\n",
      "Epoch 89/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9850 - loss: 0.0766 - val_accuracy: 0.8908 - val_loss: 0.3900\n",
      "Epoch 90/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9764 - loss: 0.0805 - val_accuracy: 0.8908 - val_loss: 0.3956\n",
      "Epoch 91/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9765 - loss: 0.1039 - val_accuracy: 0.8908 - val_loss: 0.4023\n",
      "Epoch 92/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9887 - loss: 0.0534 - val_accuracy: 0.8824 - val_loss: 0.3994\n",
      "Epoch 93/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9879 - loss: 0.0617 - val_accuracy: 0.8908 - val_loss: 0.4130\n",
      "Epoch 94/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9883 - loss: 0.0771 - val_accuracy: 0.8908 - val_loss: 0.4034\n",
      "Epoch 95/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9880 - loss: 0.0675 - val_accuracy: 0.8908 - val_loss: 0.4051\n",
      "Epoch 96/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9866 - loss: 0.0733 - val_accuracy: 0.8908 - val_loss: 0.4196\n",
      "Epoch 97/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9854 - loss: 0.0607 - val_accuracy: 0.8908 - val_loss: 0.4158\n",
      "Epoch 98/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9830 - loss: 0.0758 - val_accuracy: 0.8908 - val_loss: 0.4171\n",
      "Epoch 99/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9965 - loss: 0.0429 - val_accuracy: 0.8908 - val_loss: 0.4268\n",
      "Epoch 100/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9867 - loss: 0.0536 - val_accuracy: 0.8824 - val_loss: 0.4206\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Test Accuracy: 88.23529%\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Generating a synthetic dataset with 8 features and 396 samples for demonstration\n",
    "# # In practice, you would load your actual dataset here\n",
    "# np.random.seed(42)\n",
    "# X = np.random.rand(396, 8)  # 396 samples, 8 features\n",
    "# y = np.random.randint(0, 2, 396)  # Binary target (0 or 1)\n",
    "\n",
    "# # Splitting the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardizing the features (helps with model convergence)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Building a simple ANN model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer with 8 features and a hidden layer with 16 neurons (ReLU activation)\n",
    "model.add(Dense(16, input_dim=8, activation='relu'))\n",
    "\n",
    "# Adding a second hidden layer with 8 neurons (ReLU activation)\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Output layer for binary classification (Sigmoid activation)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compiling the model with binary cross-entropy loss and Adam optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Training the model (50 epochs, batch size of 10)\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\")  # Convert probabilities to binary labels (0 or 1)\n",
    "\n",
    "# Evaluating the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.5f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal parameters are: {'C': 29.763514416313132, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Accuracy: 0.86076\n",
      "Recall: 0.83\n",
      "Precision: 0.95745\n",
      "F1 Score: 0.89\n",
      "Cohen's Kappa: 0.70\n",
      "Confusion Matrix:\n",
      "[[23  2]\n",
      " [ 9 45]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "400 fits failed out of a total of 800.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 75, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1204, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'l1', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1052: UserWarning: One or more of the test scores are non-finite: [0.5031746  0.5031746  0.91775794 0.91775794        nan        nan\n",
      "        nan        nan 0.74375    0.7469246  0.92093254 0.91775794\n",
      "        nan        nan        nan        nan 0.8860119  0.8860119\n",
      " 0.92093254 0.92093254        nan        nan        nan        nan\n",
      " 0.91140873 0.91140873 0.92728175 0.92093254        nan        nan\n",
      "        nan        nan 0.91775794 0.91775794 0.93040675 0.92093254\n",
      "        nan        nan        nan        nan 0.92410714 0.92410714\n",
      " 0.92410714 0.92093254        nan        nan        nan        nan\n",
      " 0.92410714 0.92410714 0.92728175 0.92093254        nan        nan\n",
      "        nan        nan 0.92098214 0.92410714 0.92410714 0.92093254\n",
      "        nan        nan        nan        nan 0.92415675 0.92093254\n",
      " 0.93045635 0.92093254        nan        nan        nan        nan\n",
      " 0.93045635 0.92093254 0.93675595 0.92093254        nan        nan\n",
      "        nan        nan 0.93675595 0.92093254 0.93670635 0.92093254\n",
      "        nan        nan        nan        nan 0.93978175 0.92093254\n",
      " 0.93988095 0.92093254        nan        nan        nan        nan\n",
      " 0.93660714 0.92093254 0.94305556 0.92093254        nan        nan\n",
      "        nan        nan 0.93025794 0.92093254 0.94613095 0.92093254\n",
      "        nan        nan        nan        nan 0.93343254 0.92093254\n",
      " 0.93348214 0.92093254        nan        nan        nan        nan\n",
      " 0.93343254 0.92093254 0.93348214 0.92093254        nan        nan\n",
      "        nan        nan 0.93343254 0.92093254 0.93030754 0.92093254\n",
      "        nan        nan        nan        nan 0.93343254 0.92093254\n",
      " 0.93973214 0.92093254        nan        nan        nan        nan\n",
      " 0.93343254 0.92093254 0.93030754 0.92093254        nan        nan\n",
      "        nan        nan 0.93343254 0.92093254 0.93025794 0.92093254\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix, cohen_kappa_score, f1_score\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid for Logistic Regression\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C': np.logspace(-4, 4, 20),\n",
    "    'solver': ['liblinear', 'saga']  # solvers that support l1, l2, and elasticnet penalties\n",
    "}\n",
    "\n",
    "# param_grid = {\n",
    "#     'penalty': ['l1'],\n",
    "#     'C': [0.0885],\n",
    "#     'solver': ['liblinear']  # solvers that support l1, l2, and elasticnet penalties\n",
    "# }\n",
    "\n",
    "# Initialize the Logistic Regression classifier\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Initialize GridSearchCV with cross-validation\n",
    "grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model with GridSearchCV to find the best parameters\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the optimal parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"The optimal parameters are: {best_params}\")\n",
    "\n",
    "# Train the Logistic Regression classifier with the optimal parameters\n",
    "logreg_optimal = LogisticRegression(**best_params)\n",
    "logreg_optimal.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = logreg_optimal.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"Cohen's Kappa: {kappa:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96203\n",
      "Recall: 0.96296\n",
      "Precision: 0.98113\n",
      "F1 Score: 0.97\n",
      "Cohen's Kappa: 0.91\n",
      "Confusion Matrix:\n",
      "[[24  1]\n",
      " [ 2 52]]\n"
     ]
    }
   ],
   "source": [
    "# selected_features = ['feature1', 'feature2', 'feature3']  # Only use these features\n",
    "# X_train_selected = X_train[selected_features]\n",
    "# X_test_selected = X_test[selected_features]\n",
    "\n",
    "# Train Random Forest on the selected features\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the same selected features\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"Cohen's Kappa: {kappa:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'weight', 'gender', 'cr', 'al', 'gl', 'na', 'ca', 'k', 'cl',\n",
       "       'pr', 'wbc', 'rbc', 'hg', 'plt', 'class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cr</th>\n",
       "      <th>age</th>\n",
       "      <th>hg</th>\n",
       "      <th>al</th>\n",
       "      <th>gender</th>\n",
       "      <th>na</th>\n",
       "      <th>gl</th>\n",
       "      <th>ca</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>249.43</td>\n",
       "      <td>72.0</td>\n",
       "      <td>12.457143</td>\n",
       "      <td>34.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>35.721429</td>\n",
       "      <td>2.43</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>216.05</td>\n",
       "      <td>76.0</td>\n",
       "      <td>11.300000</td>\n",
       "      <td>41.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>36.107143</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>155.40</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>33.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>36.158571</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>127.50</td>\n",
       "      <td>65.0</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>41.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>32.994286</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>172.71</td>\n",
       "      <td>59.0</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>39.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>37.908571</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cr   age         hg    al  gender     na         gl    ca  class\n",
       "0  249.43  72.0  12.457143  34.9     1.0  142.0  35.721429  2.43    1.0\n",
       "1  216.05  76.0  11.300000  41.3     1.0  145.0  36.107143  2.40    1.0\n",
       "2  155.40  60.0   8.400000  33.7     1.0  135.0  36.158571  2.00    1.0\n",
       "3  127.50  65.0  11.700000  41.8     0.0  138.0  32.994286  2.80    1.0\n",
       "4  172.71  59.0  13.800000  39.7     1.0  128.0  37.908571  2.20    1.0"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=14)\n",
    "\n",
    "# Perform the imputation\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "df_imputed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_imputed = df_imputed.round(1)\n",
    "X = df_imputed.drop(columns='class')\n",
    "y = df_imputed['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MicroChannel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.6138 - loss: 0.6558 - val_accuracy: 0.7563 - val_loss: 0.5818\n",
      "Epoch 2/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7768 - loss: 0.5820 - val_accuracy: 0.8235 - val_loss: 0.5126\n",
      "Epoch 3/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8659 - loss: 0.5010 - val_accuracy: 0.8487 - val_loss: 0.4510\n",
      "Epoch 4/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8530 - loss: 0.4323 - val_accuracy: 0.8571 - val_loss: 0.3948\n",
      "Epoch 5/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9045 - loss: 0.3857 - val_accuracy: 0.8908 - val_loss: 0.3516\n",
      "Epoch 6/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9086 - loss: 0.3406 - val_accuracy: 0.8908 - val_loss: 0.3237\n",
      "Epoch 7/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9437 - loss: 0.2619 - val_accuracy: 0.8992 - val_loss: 0.3044\n",
      "Epoch 8/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9507 - loss: 0.2229 - val_accuracy: 0.8992 - val_loss: 0.2944\n",
      "Epoch 9/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9484 - loss: 0.2127 - val_accuracy: 0.8992 - val_loss: 0.2889\n",
      "Epoch 10/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9241 - loss: 0.2346 - val_accuracy: 0.8992 - val_loss: 0.2867\n",
      "Epoch 11/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9354 - loss: 0.1939 - val_accuracy: 0.8992 - val_loss: 0.2823\n",
      "Epoch 12/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9422 - loss: 0.1771 - val_accuracy: 0.8992 - val_loss: 0.2817\n",
      "Epoch 13/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9268 - loss: 0.1868 - val_accuracy: 0.8992 - val_loss: 0.2785\n",
      "Epoch 14/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9332 - loss: 0.1662 - val_accuracy: 0.8992 - val_loss: 0.2812\n",
      "Epoch 15/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9311 - loss: 0.2088 - val_accuracy: 0.9076 - val_loss: 0.2782\n",
      "Epoch 16/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9362 - loss: 0.1489 - val_accuracy: 0.9076 - val_loss: 0.2796\n",
      "Epoch 17/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9176 - loss: 0.1894 - val_accuracy: 0.9076 - val_loss: 0.2814\n",
      "Epoch 18/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9585 - loss: 0.1384 - val_accuracy: 0.9076 - val_loss: 0.2802\n",
      "Epoch 19/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9319 - loss: 0.1620 - val_accuracy: 0.9076 - val_loss: 0.2795\n",
      "Epoch 20/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9441 - loss: 0.1344 - val_accuracy: 0.9076 - val_loss: 0.2815\n",
      "Epoch 21/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9230 - loss: 0.1824 - val_accuracy: 0.9076 - val_loss: 0.2813\n",
      "Epoch 22/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9580 - loss: 0.1086 - val_accuracy: 0.9076 - val_loss: 0.2817\n",
      "Epoch 23/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9382 - loss: 0.1225 - val_accuracy: 0.9076 - val_loss: 0.2835\n",
      "Epoch 24/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9310 - loss: 0.1293 - val_accuracy: 0.9076 - val_loss: 0.2824\n",
      "Epoch 25/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9221 - loss: 0.1418 - val_accuracy: 0.9076 - val_loss: 0.2828\n",
      "Epoch 26/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9306 - loss: 0.1514 - val_accuracy: 0.9076 - val_loss: 0.2843\n",
      "Epoch 27/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9166 - loss: 0.1704 - val_accuracy: 0.9076 - val_loss: 0.2811\n",
      "Epoch 28/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9275 - loss: 0.1828 - val_accuracy: 0.9076 - val_loss: 0.2802\n",
      "Epoch 29/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9404 - loss: 0.1042 - val_accuracy: 0.9076 - val_loss: 0.2825\n",
      "Epoch 30/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9444 - loss: 0.1090 - val_accuracy: 0.9160 - val_loss: 0.2817\n",
      "Epoch 31/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9326 - loss: 0.1376 - val_accuracy: 0.9076 - val_loss: 0.2840\n",
      "Epoch 32/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9530 - loss: 0.1047 - val_accuracy: 0.9160 - val_loss: 0.2826\n",
      "Epoch 33/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9530 - loss: 0.1123 - val_accuracy: 0.9076 - val_loss: 0.2824\n",
      "Epoch 34/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9608 - loss: 0.1039 - val_accuracy: 0.9160 - val_loss: 0.2808\n",
      "Epoch 35/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9655 - loss: 0.1008 - val_accuracy: 0.9160 - val_loss: 0.2864\n",
      "Epoch 36/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9377 - loss: 0.1513 - val_accuracy: 0.9160 - val_loss: 0.2840\n",
      "Epoch 37/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9494 - loss: 0.1170 - val_accuracy: 0.9160 - val_loss: 0.2839\n",
      "Epoch 38/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9381 - loss: 0.1164 - val_accuracy: 0.9160 - val_loss: 0.2829\n",
      "Epoch 39/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9346 - loss: 0.1236 - val_accuracy: 0.9160 - val_loss: 0.2821\n",
      "Epoch 40/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9313 - loss: 0.1335 - val_accuracy: 0.9076 - val_loss: 0.2890\n",
      "Epoch 41/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9368 - loss: 0.1354 - val_accuracy: 0.9076 - val_loss: 0.2878\n",
      "Epoch 42/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9415 - loss: 0.1268 - val_accuracy: 0.9076 - val_loss: 0.2929\n",
      "Epoch 43/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9422 - loss: 0.1136 - val_accuracy: 0.9160 - val_loss: 0.2820\n",
      "Epoch 44/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9599 - loss: 0.0995 - val_accuracy: 0.9160 - val_loss: 0.2861\n",
      "Epoch 45/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9430 - loss: 0.1259 - val_accuracy: 0.9076 - val_loss: 0.2905\n",
      "Epoch 46/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9573 - loss: 0.1071 - val_accuracy: 0.9160 - val_loss: 0.2889\n",
      "Epoch 47/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9499 - loss: 0.1253 - val_accuracy: 0.9160 - val_loss: 0.2867\n",
      "Epoch 48/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9606 - loss: 0.1215 - val_accuracy: 0.9076 - val_loss: 0.2886\n",
      "Epoch 49/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9615 - loss: 0.1081 - val_accuracy: 0.9160 - val_loss: 0.2835\n",
      "Epoch 50/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.0939 - val_accuracy: 0.9076 - val_loss: 0.2896\n",
      "Epoch 51/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9446 - loss: 0.1135 - val_accuracy: 0.9076 - val_loss: 0.2900\n",
      "Epoch 52/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9478 - loss: 0.1172 - val_accuracy: 0.9160 - val_loss: 0.2894\n",
      "Epoch 53/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9692 - loss: 0.1119 - val_accuracy: 0.9160 - val_loss: 0.2868\n",
      "Epoch 54/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9518 - loss: 0.1051 - val_accuracy: 0.9244 - val_loss: 0.2888\n",
      "Epoch 55/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9487 - loss: 0.1565 - val_accuracy: 0.9160 - val_loss: 0.2921\n",
      "Epoch 56/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9689 - loss: 0.0980 - val_accuracy: 0.9160 - val_loss: 0.2853\n",
      "Epoch 57/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9656 - loss: 0.1094 - val_accuracy: 0.9160 - val_loss: 0.2969\n",
      "Epoch 58/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9668 - loss: 0.0914 - val_accuracy: 0.9160 - val_loss: 0.2893\n",
      "Epoch 59/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9764 - loss: 0.0645 - val_accuracy: 0.9160 - val_loss: 0.2909\n",
      "Epoch 60/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9615 - loss: 0.1020 - val_accuracy: 0.9160 - val_loss: 0.2903\n",
      "Epoch 61/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9686 - loss: 0.0794 - val_accuracy: 0.9160 - val_loss: 0.2909\n",
      "Epoch 62/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9768 - loss: 0.0906 - val_accuracy: 0.9160 - val_loss: 0.2913\n",
      "Epoch 63/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9744 - loss: 0.0715 - val_accuracy: 0.9160 - val_loss: 0.2910\n",
      "Epoch 64/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9858 - loss: 0.0810 - val_accuracy: 0.9160 - val_loss: 0.2962\n",
      "Epoch 65/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9820 - loss: 0.0945 - val_accuracy: 0.9160 - val_loss: 0.2963\n",
      "Epoch 66/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9791 - loss: 0.0855 - val_accuracy: 0.9160 - val_loss: 0.2917\n",
      "Epoch 67/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9747 - loss: 0.1046 - val_accuracy: 0.9160 - val_loss: 0.2947\n",
      "Epoch 68/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9630 - loss: 0.1108 - val_accuracy: 0.9160 - val_loss: 0.2971\n",
      "Epoch 69/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9856 - loss: 0.0932 - val_accuracy: 0.9160 - val_loss: 0.3020\n",
      "Epoch 70/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9759 - loss: 0.0937 - val_accuracy: 0.9160 - val_loss: 0.2978\n",
      "Epoch 71/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9778 - loss: 0.0750 - val_accuracy: 0.9160 - val_loss: 0.2945\n",
      "Epoch 72/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9856 - loss: 0.0719 - val_accuracy: 0.9160 - val_loss: 0.2988\n",
      "Epoch 73/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9872 - loss: 0.0706 - val_accuracy: 0.9160 - val_loss: 0.3006\n",
      "Epoch 74/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9736 - loss: 0.0875 - val_accuracy: 0.9160 - val_loss: 0.3016\n",
      "Epoch 75/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9773 - loss: 0.0820 - val_accuracy: 0.9160 - val_loss: 0.3035\n",
      "Epoch 76/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9859 - loss: 0.0676 - val_accuracy: 0.9160 - val_loss: 0.3037\n",
      "Epoch 77/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9859 - loss: 0.0650 - val_accuracy: 0.9160 - val_loss: 0.3034\n",
      "Epoch 78/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9834 - loss: 0.0656 - val_accuracy: 0.9160 - val_loss: 0.3055\n",
      "Epoch 79/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9627 - loss: 0.1204 - val_accuracy: 0.9160 - val_loss: 0.3050\n",
      "Epoch 80/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9797 - loss: 0.0861 - val_accuracy: 0.9160 - val_loss: 0.3098\n",
      "Epoch 81/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9837 - loss: 0.0665 - val_accuracy: 0.9160 - val_loss: 0.3039\n",
      "Epoch 82/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9893 - loss: 0.0687 - val_accuracy: 0.9160 - val_loss: 0.3098\n",
      "Epoch 83/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9734 - loss: 0.0911 - val_accuracy: 0.9160 - val_loss: 0.3152\n",
      "Epoch 84/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9845 - loss: 0.0709 - val_accuracy: 0.9160 - val_loss: 0.3111\n",
      "Epoch 85/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9806 - loss: 0.1059 - val_accuracy: 0.9160 - val_loss: 0.3100\n",
      "Epoch 86/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9723 - loss: 0.0986 - val_accuracy: 0.9160 - val_loss: 0.3108\n",
      "Epoch 87/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9742 - loss: 0.0706 - val_accuracy: 0.9160 - val_loss: 0.3124\n",
      "Epoch 88/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9866 - loss: 0.0752 - val_accuracy: 0.9160 - val_loss: 0.3103\n",
      "Epoch 89/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9760 - loss: 0.0721 - val_accuracy: 0.9160 - val_loss: 0.3188\n",
      "Epoch 90/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9877 - loss: 0.0524 - val_accuracy: 0.9160 - val_loss: 0.3134\n",
      "Epoch 91/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9887 - loss: 0.0548 - val_accuracy: 0.9160 - val_loss: 0.3163\n",
      "Epoch 92/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9783 - loss: 0.0709 - val_accuracy: 0.9160 - val_loss: 0.3137\n",
      "Epoch 93/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9747 - loss: 0.0833 - val_accuracy: 0.9160 - val_loss: 0.3206\n",
      "Epoch 94/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9717 - loss: 0.0780 - val_accuracy: 0.9160 - val_loss: 0.3174\n",
      "Epoch 95/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9869 - loss: 0.0622 - val_accuracy: 0.9160 - val_loss: 0.3202\n",
      "Epoch 96/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9677 - loss: 0.0847 - val_accuracy: 0.9160 - val_loss: 0.3188\n",
      "Epoch 97/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9700 - loss: 0.0959 - val_accuracy: 0.9160 - val_loss: 0.3211\n",
      "Epoch 98/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9790 - loss: 0.0776 - val_accuracy: 0.9160 - val_loss: 0.3202\n",
      "Epoch 99/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9812 - loss: 0.0557 - val_accuracy: 0.9160 - val_loss: 0.3227\n",
      "Epoch 100/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9705 - loss: 0.0681 - val_accuracy: 0.9160 - val_loss: 0.3254\n",
      "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001CFC4EC2FC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/stepWARNING:tensorflow:6 out of the last 10 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001CFC4EC2FC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Test Accuracy: 91.60%\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Generating a synthetic dataset with 8 features and 396 samples for demonstration\n",
    "# # In practice, you would load your actual dataset here\n",
    "# np.random.seed(42)\n",
    "# X = np.random.rand(396, 8)  # 396 samples, 8 features\n",
    "# y = np.random.randint(0, 2, 396)  # Binary target (0 or 1)\n",
    "\n",
    "# # Splitting the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardizing the features (helps with model convergence)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Building a simple ANN model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer with 8 features and a hidden layer with 16 neurons (ReLU activation)\n",
    "model.add(Dense(16, input_dim=8, activation='relu'))\n",
    "\n",
    "# Adding a second hidden layer with 8 neurons (ReLU activation)\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Output layer for binary classification (Sigmoid activation)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compiling the model with binary cross-entropy loss and Adam optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Training the model (50 epochs, batch size of 10)\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\")  # Convert probabilities to binary labels (0 or 1)\n",
    "\n",
    "# Evaluating the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_imputed = df_imputed.drop(columns='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_imputed = df_imputed.round(1)\n",
    "X = df_imputed.drop(columns='class')\n",
    "y = df_imputed['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# from sklearn.inspection import permutation_importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import RFE\n",
    "\n",
    "# model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# # Use RFE to select top 2 features\n",
    "# rfe = RFE(model, n_features_to_select=2)\n",
    "# fit = rfe.fit(X, y)\n",
    "\n",
    "# # Print selected features\n",
    "# selected_features = [feature for feature, selected in zip(X.columns, fit.support_) if selected]\n",
    "# print(f\"Selected Features: {selected_features}\")\n",
    "\n",
    "# # Rank all features\n",
    "# ranking = pd.DataFrame({'Feature': X.columns, 'Ranking': fit.ranking_})\n",
    "# print(ranking.sort_values(by='Ranking'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # d = df_imputed.round(1)\n",
    "# d = df_imputed[['ca','gender','hg','al','na','class','cr']]\n",
    "\n",
    "# X = d.drop(columns='class')\n",
    "# y = d['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Train the XGBoost Classifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hg</th>\n",
       "      <th>al</th>\n",
       "      <th>gender</th>\n",
       "      <th>na</th>\n",
       "      <th>gl</th>\n",
       "      <th>ca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>45.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>36.371429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>35.178571</td>\n",
       "      <td>2.195714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>63.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>35.700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>32.842857</td>\n",
       "      <td>2.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>45.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>36.120000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>43.600000</td>\n",
       "      <td>2.128571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>27.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>139.428571</td>\n",
       "      <td>38.335714</td>\n",
       "      <td>2.390714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>48.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>35.650000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>35.792857</td>\n",
       "      <td>2.234286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>34.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>32.900000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>2.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>61.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>35.370000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.142857</td>\n",
       "      <td>31.065714</td>\n",
       "      <td>1.990714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>52.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>30.700000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>2.190714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>41.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>32.487143</td>\n",
       "      <td>2.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>68.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>36.520000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>28.194286</td>\n",
       "      <td>2.113571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age    hg         al  gender          na         gl        ca\n",
       "78   45.0  11.7  36.371429     0.0  133.000000  35.178571  2.195714\n",
       "371  63.0  10.9  35.700000     0.0  141.000000  32.842857  2.200000\n",
       "248  45.0  15.0  36.120000     0.0  141.000000  43.600000  2.128571\n",
       "55   27.0  13.2  38.500000     1.0  139.428571  38.335714  2.390714\n",
       "390  48.0  13.5  35.650000     1.0  134.000000  35.792857  2.234286\n",
       "..    ...   ...        ...     ...         ...        ...       ...\n",
       "364  34.0  10.1  32.900000     1.0  134.000000  20.200000  2.470000\n",
       "82   61.0  10.8  35.370000     0.0  134.142857  31.065714  1.990714\n",
       "114  52.0   9.5  30.700000     1.0  125.000000  35.500000  2.190714\n",
       "3    65.0  11.7  41.800000     0.0  138.000000  32.487143  2.800000\n",
       "18   68.0  13.1  36.520000     1.0  133.000000  28.194286  2.113571\n",
       "\n",
       "[79 rows x 7 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78     0.0\n",
       "371    1.0\n",
       "248    0.0\n",
       "55     1.0\n",
       "390    1.0\n",
       "      ... \n",
       "364    1.0\n",
       "82     0.0\n",
       "114    1.0\n",
       "3      1.0\n",
       "18     1.0\n",
       "Name: class, Length: 79, dtype: float64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_ = np.array([716.230,60.0, 84.0,38.800000,\t1.0,121.0,31.042857,2.100000,77.000000,4.5])\n",
    "# x_ = x_.reshape(1, -1)\n",
    "\n",
    "# # single_instance = np.array([4.5, 2.3, 1.3, 0.2, 3.1])\n",
    "\n",
    "# # # Reshape it into a 2D array\n",
    "# # single_instance_reshaped = single_instance.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Load the saved XGBoost model\n",
    "# with open(\"model_folder/xgboost_ckd_model.pkl\", \"rb\") as file:\n",
    "#     m = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_ = m.predict(x_)\n",
    "# y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78     0.0\n",
       "371    1.0\n",
       "248    0.0\n",
       "55     1.0\n",
       "390    1.0\n",
       "      ... \n",
       "364    1.0\n",
       "82     0.0\n",
       "114    1.0\n",
       "3      1.0\n",
       "18     1.0\n",
       "Name: class, Length: 79, dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as model_folder\\xgboost_ckd_model_no_scr.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "folder_name = \"model_folder\"\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "    print(f\"Folder '{folder_name}' created.\")\n",
    "\n",
    "# Step 6: Save the model in the new folder\n",
    "# model_path = os.path.join(folder_name, 'xgboost_ckd_model_no_alglca.pkl')\n",
    "# model_path = os.path.join(folder_name, 'xgboost_ckd_model.pkl')\n",
    "model_path = os.path.join(folder_name, 'xgboost_ckd_model_no_scr.pkl')\n",
    "\n",
    "\n",
    "with open(model_path, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "print(f\"Model saved as {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
